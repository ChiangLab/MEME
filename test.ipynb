{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41ff0c5-ee3d-4e5a-a005-0e99092ddfe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./ImageBind\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytorchvideo@ git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
      "  Using cached pytorchvideo-0.1.5-py3-none-any.whl\n",
      "Collecting torch==1.13.0\n",
      "  Using cached torch-1.13.0-cp39-cp39-manylinux1_x86_64.whl (890.2 MB)\n",
      "Collecting torchvision==0.14.0\n",
      "  Using cached torchvision-0.14.0-cp39-cp39-manylinux1_x86_64.whl (24.3 MB)\n",
      "Collecting torchaudio==0.13.0\n",
      "  Using cached torchaudio-0.13.0-cp39-cp39-manylinux1_x86_64.whl (4.2 MB)\n",
      "Collecting timm==0.6.7\n",
      "  Using cached timm-0.6.7-py3-none-any.whl (509 kB)\n",
      "Collecting ftfy\n",
      "  Using cached ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Collecting regex\n",
      "  Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "Collecting einops\n",
      "  Using cached einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "Collecting fvcore\n",
      "  Using cached fvcore-0.1.5.post20221221-py3-none-any.whl\n",
      "Collecting eva-decord==0.6.1\n",
      "  Using cached eva_decord-0.6.1-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
      "Collecting iopath\n",
      "  Using cached iopath-0.1.10-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.9/site-packages (from imagebind==0.1.0) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from imagebind==0.1.0) (3.6.3)\n",
      "Collecting types-regex\n",
      "  Using cached types_regex-2023.8.8.0-py3-none-any.whl (5.1 kB)\n",
      "Collecting mayavi\n",
      "  Using cached mayavi-4.8.1-cp39-cp39-linux_x86_64.whl\n",
      "Collecting cartopy\n",
      "  Using cached Cartopy-0.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch==1.13.0->imagebind==0.1.0) (4.4.0)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from torchvision==0.14.0->imagebind==0.1.0) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision==0.14.0->imagebind==0.1.0) (9.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->imagebind==0.1.0) (65.6.3)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->imagebind==0.1.0) (0.38.4)\n",
      "Collecting pyproj>=3.1.0\n",
      "  Using cached pyproj-3.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.9 MB)\n",
      "Collecting shapely>=1.7\n",
      "  Using cached shapely-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "Requirement already satisfied: packaging>=20 in /opt/conda/lib/python3.9/site-packages (from cartopy->imagebind==0.1.0) (23.0)\n",
      "Collecting pyshp>=2.1\n",
      "  Using cached pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->imagebind==0.1.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->imagebind==0.1.0) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->imagebind==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->imagebind==0.1.0) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->imagebind==0.1.0) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->imagebind==0.1.0) (1.0.7)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.9/site-packages (from ftfy->imagebind==0.1.0) (0.2.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from fvcore->imagebind==0.1.0) (4.64.1)\n",
      "Collecting termcolor>=1.1\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from fvcore->imagebind==0.1.0) (5.4.1)\n",
      "Collecting yacs>=0.1.6\n",
      "  Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.9/site-packages (from fvcore->imagebind==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.9/site-packages (from iopath->imagebind==0.1.0) (2.7.0)\n",
      "Collecting traitsui>=7.0.0\n",
      "  Using cached traitsui-8.0.0-py3-none-any.whl (1.5 MB)\n",
      "Collecting vtk\n",
      "  Using cached vtk-9.2.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (79.3 MB)\n",
      "Collecting apptools\n",
      "  Using cached apptools-5.2.1-py3-none-any.whl (229 kB)\n",
      "Collecting pyface>=6.1.1\n",
      "  Using cached pyface-8.0.0-py3-none-any.whl (1.3 MB)\n",
      "Collecting envisage\n",
      "  Using cached envisage-7.0.3-py3-none-any.whl (268 kB)\n",
      "Collecting traits>=6.0.0\n",
      "  Using cached traits-6.4.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.9/site-packages (from mayavi->imagebind==0.1.0) (2.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from pytorchvideo@ git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d->imagebind==0.1.0) (3.0)\n",
      "Collecting parameterized\n",
      "  Using cached parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Collecting av\n",
      "  Using cached av-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /opt/conda/lib/python3.9/site-packages (from pyface>=6.1.1->mayavi->imagebind==0.1.0) (4.13.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from pyproj>=3.1.0->cartopy->imagebind==0.1.0) (2022.12.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->imagebind==0.1.0) (1.16.0)\n",
      "Collecting configobj\n",
      "  Using cached configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision==0.14.0->imagebind==0.1.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision==0.14.0->imagebind==0.1.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision==0.14.0->imagebind==0.1.0) (1.26.14)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=3.6->pyface>=6.1.1->mayavi->imagebind==0.1.0) (3.13.0)\n",
      "Building wheels for collected packages: imagebind\n",
      "  Building wheel for imagebind (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imagebind: filename=imagebind-0.1.0-py3-none-any.whl size=27969 sha256=3b572098f581f2b128e8c8232d7269a1cfc4d0da236aac7a759bd1a92de5b26f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-spd3bddk/wheels/15/d5/57/9f60b1256b436b67dceac96201d8bc2eebd9fd320f633e190f\n",
      "Successfully built imagebind\n",
      "Installing collected packages: types-regex, av, yacs, traits, termcolor, shapely, regex, pyshp, pyproj, parameterized, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, iopath, ftfy, eva-decord, einops, configobj, pyface, nvidia-cudnn-cu11, fvcore, vtk, traitsui, torch, pytorchvideo, cartopy, torchvision, torchaudio, apptools, timm, envisage, mayavi, imagebind\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1+cpu\n",
      "    Uninstalling torch-1.13.1+cpu:\n",
      "      Successfully uninstalled torch-1.13.1+cpu\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.14.1+cpu\n",
      "    Uninstalling torchvision-0.14.1+cpu:\n",
      "      Successfully uninstalled torchvision-0.14.1+cpu\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.13.1+cpu\n",
      "    Uninstalling torchaudio-0.13.1+cpu:\n",
      "      Successfully uninstalled torchaudio-0.13.1+cpu\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchdata 0.5.1 requires torch==1.13.1, but you have torch 1.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed apptools-5.2.1 av-10.0.0 cartopy-0.22.0 configobj-5.0.8 einops-0.6.1 envisage-7.0.3 eva-decord-0.6.1 ftfy-6.1.1 fvcore-0.1.5.post20221221 imagebind-0.1.0 iopath-0.1.10 mayavi-4.8.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 parameterized-0.9.0 pyface-8.0.0 pyproj-3.6.0 pyshp-2.3.1 pytorchvideo-0.1.5 regex-2023.8.8 shapely-2.0.1 termcolor-2.3.0 timm-0.6.7 torch-1.13.0 torchaudio-0.13.0 torchvision-0.14.0 traits-6.4.2 traitsui-8.0.0 types-regex-2023.8.8.0 vtk-9.2.6 yacs-0.1.8\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-zdt_vqk1\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-zdt_vqk1\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 1fa2d89a9bb98a15e9720190e07d272a42f03d28\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.33.0.dev0) (2.28.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.33.0.dev0) (2023.8.8)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.33.0.dev0) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.33.0.dev0) (4.64.1)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.3-py3-none-any.whl (11 kB)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.33.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.33.0.dev0) (23.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0.dev0) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0.dev0) (4.4.0)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.33.0.dev0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.33.0.dev0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.33.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.33.0.dev0) (1.26.14)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.33.0.dev0-py3-none-any.whl size=7633929 sha256=b8834cc704abe4729d50b419982df0b67b5e645b40f9faec1239f37dded22018\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-u9cn3mws/wheels/f7/92/8c/752ff3bfcd3439805d8bbf641614da38ef3226e127ebea86ee\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, safetensors, typing-extensions, filelock, huggingface-hub, transformers\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "Successfully installed filelock-3.12.3 huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.0.dev0 typing-extensions-4.7.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting sagemaker>=2.140.0\n",
      "  Using cached sagemaker-2.182.0-py2.py3-none-any.whl\n",
      "Collecting transformers==4.26.1\n",
      "  Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "Collecting datasets[s3]==2.10.1\n",
      "  Using cached datasets-2.10.1-py3-none-any.whl (469 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (0.16.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (1.23.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (3.12.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (23.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (2.28.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (2023.8.8)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (2023.1.0)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (0.70.14)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (1.5.3)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (11.0.0)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (0.4.2)\n",
      "Collecting attrs<24,>=23.1.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (0.3.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (1.0.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (0.2.0)\n",
      "Collecting tblib==1.7.0\n",
      "  Using cached tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (4.13.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (3.20.2)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (0.7.5)\n",
      "Collecting jsonschema\n",
      "  Using cached jsonschema-4.19.0-py3-none-any.whl (83 kB)\n",
      "Collecting boto3<2.0,>=1.26.131\n",
      "  Downloading boto3-1.28.39-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting platformdirs\n",
      "  Using cached platformdirs-3.10.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (2.2.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.131->sagemaker>=2.140.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.131->sagemaker>=2.140.0) (0.6.0)\n",
      "Collecting botocore<1.32.0,>=1.31.39\n",
      "  Downloading botocore-1.31.39-py3-none-any.whl (11.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets[s3]==2.10.1) (2.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (4.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker>=2.140.0) (3.13.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.26.1) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.26.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.26.1) (1.26.14)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from google-pasta->sagemaker>=2.140.0) (1.16.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Using cached rpds_py-0.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting referencing>=0.28.4\n",
      "  Using cached referencing-0.30.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets[s3]==2.10.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets[s3]==2.10.1) (2022.7.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker>=2.140.0) (1.7.6.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker>=2.140.0) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.9/site-packages (from schema->sagemaker>=2.140.0) (21.6.0)\n",
      "Installing collected packages: xxhash, tblib, rpds-py, pyyaml, platformdirs, multidict, frozenlist, attrs, async-timeout, yarl, responses, referencing, botocore, aiosignal, transformers, jsonschema-specifications, aiohttp, jsonschema, boto3, sagemaker, datasets\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.2.0\n",
      "    Uninstalling attrs-22.2.0:\n",
      "      Successfully uninstalled attrs-22.2.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.70\n",
      "    Uninstalling botocore-1.29.70:\n",
      "      Successfully uninstalled botocore-1.29.70\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.33.0.dev0\n",
      "    Uninstalling transformers-4.33.0.dev0:\n",
      "      Successfully uninstalled transformers-4.33.0.dev0\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.70\n",
      "    Uninstalling boto3-1.26.70:\n",
      "      Successfully uninstalled boto3-1.26.70\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.132.0\n",
      "    Uninstalling sagemaker-2.132.0:\n",
      "      Successfully uninstalled sagemaker-2.132.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.70 requires botocore==1.29.70, but you have botocore 1.31.39 which is incompatible.\n",
      "awscli 1.27.70 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 boto3-1.28.39 botocore-1.31.39 datasets-2.10.1 frozenlist-1.4.0 jsonschema-4.19.0 jsonschema-specifications-2023.7.1 multidict-6.0.4 platformdirs-3.10.0 pyyaml-6.0.1 referencing-0.30.2 responses-0.18.0 rpds-py-0.10.0 sagemaker-2.182.0 tblib-1.7.0 transformers-4.26.1 xxhash-3.3.0 yarl-1.9.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting accelerate==0.20.3\n",
      "  Using cached accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from accelerate==0.20.3) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from accelerate==0.20.3) (1.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from accelerate==0.20.3) (23.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from accelerate==0.20.3) (6.0.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from accelerate==0.20.3) (5.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->accelerate==0.20.3) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->accelerate==0.20.3) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->accelerate==0.20.3) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->accelerate==0.20.3) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->accelerate==0.20.3) (11.7.99)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate==0.20.3) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate==0.20.3) (65.6.3)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.16.0\n",
      "    Uninstalling accelerate-0.16.0:\n",
      "      Successfully uninstalled accelerate-0.16.0\n",
      "Successfully installed accelerate-0.20.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ml.m5.4xlarge\n",
    "!pip install ImageBind/.\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install \"sagemaker>=2.140.0\" \"transformers==4.26.1\" \"datasets[s3]==2.10.1\" --upgrade\n",
    "!pip install accelerate==0.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe30c5f-fcdc-4e3b-a7fc-12a33eb1e06f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.9/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from ImageBind.imagebind import data\n",
    "import torch\n",
    "from imagebind.models import imagebind_model\n",
    "from imagebind.models.imagebind_model import ModalityType\n",
    "\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO # Python 3.\n",
    "from datasets import load_dataset,Dataset,DatasetDict,concatenate_datasets\n",
    "\n",
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07966dc-8947-4712-a130-c530a6d827a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataframe: 210\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival</th>\n",
       "      <th>eddischarge</th>\n",
       "      <th>admission</th>\n",
       "      <th>discharge</th>\n",
       "      <th>triage</th>\n",
       "      <th>medrecon</th>\n",
       "      <th>vitals</th>\n",
       "      <th>pyxis</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37887480</th>\n",
       "      <td>Patient 10014729, a 21 year old white - other ...</td>\n",
       "      <td>The ED disposition was admitted at 2125-03-19 ...</td>\n",
       "      <td>The patient was admitted at 2125-03-19 16:58:00.</td>\n",
       "      <td>The patient's discharge disposition was: home ...</td>\n",
       "      <td>At triage: temperature was 99.1, pulse was 90....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2125-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34176810</th>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>The ED disposition was admitted at 2154-02-05 ...</td>\n",
       "      <td>The patient was admitted at 2154-02-05 21:58:00.</td>\n",
       "      <td>The patient's discharge disposition was: home ...</td>\n",
       "      <td>At triage: temperature was 97.7, pulse was 74....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103106</th>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>The ED disposition was home at 2154-08-03 22:2...</td>\n",
       "      <td>The patient was not admitted.</td>\n",
       "      <td>The patient was not admitted.</td>\n",
       "      <td>At triage: temperature was 96.2, pulse was 74....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38797992</th>\n",
       "      <td>Patient 10020640, a 91 year old white female, ...</td>\n",
       "      <td>The ED disposition was admitted at 2153-02-13 ...</td>\n",
       "      <td>The patient was admitted at 2153-02-13 00:22:00.</td>\n",
       "      <td>The patient's discharge disposition was: skill...</td>\n",
       "      <td>At triage: temperature was 99.2, pulse was 130...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2153-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33473053</th>\n",
       "      <td>Patient 10015272, a 78 year old white female, ...</td>\n",
       "      <td>The ED disposition was admitted at 2137-06-12 ...</td>\n",
       "      <td>The patient was admitted at 2137-06-12 18:36:00.</td>\n",
       "      <td>The patient's discharge disposition was: home ...</td>\n",
       "      <td>At triage: temperature was 97.5, pulse was 118...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2137-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arrival  \\\n",
       "37887480  Patient 10014729, a 21 year old white - other ...   \n",
       "34176810  Patient 10018328, a 83 year old white female, ...   \n",
       "32103106  Patient 10018328, a 83 year old white female, ...   \n",
       "38797992  Patient 10020640, a 91 year old white female, ...   \n",
       "33473053  Patient 10015272, a 78 year old white female, ...   \n",
       "\n",
       "                                                eddischarge  \\\n",
       "37887480  The ED disposition was admitted at 2125-03-19 ...   \n",
       "34176810  The ED disposition was admitted at 2154-02-05 ...   \n",
       "32103106  The ED disposition was home at 2154-08-03 22:2...   \n",
       "38797992  The ED disposition was admitted at 2153-02-13 ...   \n",
       "33473053  The ED disposition was admitted at 2137-06-12 ...   \n",
       "\n",
       "                                                 admission  \\\n",
       "37887480  The patient was admitted at 2125-03-19 16:58:00.   \n",
       "34176810  The patient was admitted at 2154-02-05 21:58:00.   \n",
       "32103106                     The patient was not admitted.   \n",
       "38797992  The patient was admitted at 2153-02-13 00:22:00.   \n",
       "33473053  The patient was admitted at 2137-06-12 18:36:00.   \n",
       "\n",
       "                                                  discharge  \\\n",
       "37887480  The patient's discharge disposition was: home ...   \n",
       "34176810  The patient's discharge disposition was: home ...   \n",
       "32103106                      The patient was not admitted.   \n",
       "38797992  The patient's discharge disposition was: skill...   \n",
       "33473053  The patient's discharge disposition was: home ...   \n",
       "\n",
       "                                                     triage  \\\n",
       "37887480  At triage: temperature was 99.1, pulse was 90....   \n",
       "34176810  At triage: temperature was 97.7, pulse was 74....   \n",
       "32103106  At triage: temperature was 96.2, pulse was 74....   \n",
       "38797992  At triage: temperature was 99.2, pulse was 130...   \n",
       "33473053  At triage: temperature was 97.5, pulse was 118...   \n",
       "\n",
       "                                                   medrecon  \\\n",
       "37887480  The patient was previously taking the followin...   \n",
       "34176810  The patient was previously taking the followin...   \n",
       "32103106  The patient was previously taking the followin...   \n",
       "38797992  The patient was previously taking the followin...   \n",
       "33473053  The patient was previously taking the followin...   \n",
       "\n",
       "                                                     vitals  \\\n",
       "37887480  The patient had the following vitals: At 2125-...   \n",
       "34176810  The patient had the following vitals: At 2154-...   \n",
       "32103106  The patient had the following vitals: At 2154-...   \n",
       "38797992  The patient had the following vitals: At 2153-...   \n",
       "33473053  The patient had the following vitals: At 2137-...   \n",
       "\n",
       "                                                      pyxis  \\\n",
       "37887480  The patient received the following medications...   \n",
       "34176810                                                NaN   \n",
       "32103106  The patient received the following medications...   \n",
       "38797992  The patient received the following medications...   \n",
       "33473053  The patient received the following medications...   \n",
       "\n",
       "                                                      codes  \n",
       "37887480  The patient received the following diagnostic ...  \n",
       "34176810  The patient received the following diagnostic ...  \n",
       "32103106  The patient received the following diagnostic ...  \n",
       "38797992  The patient received the following diagnostic ...  \n",
       "33473053  The patient received the following diagnostic ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'chianglab-dataderivatives'\n",
    "file_path = \"mimic-iv-ed-demo-2.2/text_repr.json\"\n",
    "\n",
    "# loading in raw data\n",
    "content_object = s3.Object(bucket_name, file_path)\n",
    "file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file_content)\n",
    "df = pd.DataFrame(json_content).T\n",
    "print(\"length of dataframe: \"+ str(len(df)))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98372046-cf37-453e-9775-9faeab9a9cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival</th>\n",
       "      <th>triage</th>\n",
       "      <th>medrecon</th>\n",
       "      <th>vitals</th>\n",
       "      <th>pyxis</th>\n",
       "      <th>codes</th>\n",
       "      <th>eddischarge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37887480</th>\n",
       "      <td>Patient 10014729, a 21 year old white - other ...</td>\n",
       "      <td>At triage: temperature was 99.1, pulse was 90....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2125-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34176810</th>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 97.7, pulse was 74....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>The patient did not receive any medications.</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103106</th>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 96.2, pulse was 74....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38797992</th>\n",
       "      <td>Patient 10020640, a 91 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 99.2, pulse was 130...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2153-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33473053</th>\n",
       "      <td>Patient 10015272, a 78 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 97.5, pulse was 118...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2137-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30272878</th>\n",
       "      <td>Patient 10038999, a 45 year old white male, ar...</td>\n",
       "      <td>At triage: temperature was not recorded, pulse...</td>\n",
       "      <td>The patient was previously not taking any medi...</td>\n",
       "      <td>The patient had the following vitals: At 2131-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31628990</th>\n",
       "      <td>Patient 10009049, a 56 year old white male, ar...</td>\n",
       "      <td>At triage: temperature was 99.0, pulse was 87....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2174-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32405286</th>\n",
       "      <td>Patient 10004457, a 65 year old white male, ar...</td>\n",
       "      <td>At triage: temperature was 97.6, pulse was 103...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2141-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34391979</th>\n",
       "      <td>Patient 10004720, a 61 year old white male, ar...</td>\n",
       "      <td>At triage: temperature was not recorded, pulse...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2186-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34161260</th>\n",
       "      <td>Patient 10004720, a 61 year old white male, ar...</td>\n",
       "      <td>At triage: temperature was 97.0, pulse was 106...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2183-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arrival  \\\n",
       "37887480  Patient 10014729, a 21 year old white - other ...   \n",
       "34176810  Patient 10018328, a 83 year old white female, ...   \n",
       "32103106  Patient 10018328, a 83 year old white female, ...   \n",
       "38797992  Patient 10020640, a 91 year old white female, ...   \n",
       "33473053  Patient 10015272, a 78 year old white female, ...   \n",
       "...                                                     ...   \n",
       "30272878  Patient 10038999, a 45 year old white male, ar...   \n",
       "31628990  Patient 10009049, a 56 year old white male, ar...   \n",
       "32405286  Patient 10004457, a 65 year old white male, ar...   \n",
       "34391979  Patient 10004720, a 61 year old white male, ar...   \n",
       "34161260  Patient 10004720, a 61 year old white male, ar...   \n",
       "\n",
       "                                                     triage  \\\n",
       "37887480  At triage: temperature was 99.1, pulse was 90....   \n",
       "34176810  At triage: temperature was 97.7, pulse was 74....   \n",
       "32103106  At triage: temperature was 96.2, pulse was 74....   \n",
       "38797992  At triage: temperature was 99.2, pulse was 130...   \n",
       "33473053  At triage: temperature was 97.5, pulse was 118...   \n",
       "...                                                     ...   \n",
       "30272878  At triage: temperature was not recorded, pulse...   \n",
       "31628990  At triage: temperature was 99.0, pulse was 87....   \n",
       "32405286  At triage: temperature was 97.6, pulse was 103...   \n",
       "34391979  At triage: temperature was not recorded, pulse...   \n",
       "34161260  At triage: temperature was 97.0, pulse was 106...   \n",
       "\n",
       "                                                   medrecon  \\\n",
       "37887480  The patient was previously taking the followin...   \n",
       "34176810  The patient was previously taking the followin...   \n",
       "32103106  The patient was previously taking the followin...   \n",
       "38797992  The patient was previously taking the followin...   \n",
       "33473053  The patient was previously taking the followin...   \n",
       "...                                                     ...   \n",
       "30272878  The patient was previously not taking any medi...   \n",
       "31628990  The patient was previously taking the followin...   \n",
       "32405286  The patient was previously taking the followin...   \n",
       "34391979  The patient was previously taking the followin...   \n",
       "34161260  The patient was previously taking the followin...   \n",
       "\n",
       "                                                     vitals  \\\n",
       "37887480  The patient had the following vitals: At 2125-...   \n",
       "34176810  The patient had the following vitals: At 2154-...   \n",
       "32103106  The patient had the following vitals: At 2154-...   \n",
       "38797992  The patient had the following vitals: At 2153-...   \n",
       "33473053  The patient had the following vitals: At 2137-...   \n",
       "...                                                     ...   \n",
       "30272878  The patient had the following vitals: At 2131-...   \n",
       "31628990  The patient had the following vitals: At 2174-...   \n",
       "32405286  The patient had the following vitals: At 2141-...   \n",
       "34391979  The patient had the following vitals: At 2186-...   \n",
       "34161260  The patient had the following vitals: At 2183-...   \n",
       "\n",
       "                                                      pyxis  \\\n",
       "37887480  The patient received the following medications...   \n",
       "34176810       The patient did not receive any medications.   \n",
       "32103106  The patient received the following medications...   \n",
       "38797992  The patient received the following medications...   \n",
       "33473053  The patient received the following medications...   \n",
       "...                                                     ...   \n",
       "30272878  The patient received the following medications...   \n",
       "31628990  The patient received the following medications...   \n",
       "32405286  The patient received the following medications...   \n",
       "34391979  The patient received the following medications...   \n",
       "34161260  The patient received the following medications...   \n",
       "\n",
       "                                                      codes  eddischarge  \n",
       "37887480  The patient received the following diagnostic ...            1  \n",
       "34176810  The patient received the following diagnostic ...            1  \n",
       "32103106  The patient received the following diagnostic ...            0  \n",
       "38797992  The patient received the following diagnostic ...            1  \n",
       "33473053  The patient received the following diagnostic ...            1  \n",
       "...                                                     ...          ...  \n",
       "30272878  The patient received the following diagnostic ...            1  \n",
       "31628990  The patient received the following diagnostic ...            1  \n",
       "32405286  The patient received the following diagnostic ...            1  \n",
       "34391979  The patient received the following diagnostic ...            1  \n",
       "34161260  The patient received the following diagnostic ...            0  \n",
       "\n",
       "[210 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['eddischarge'] = [1 if 'admitted' in s.lower() else 0 for s in df['eddischarge']] # admitted = 1, Home = 0\n",
    "df['medrecon'] = df['medrecon'].fillna(\"The patient was previously not taking any medications.\")\n",
    "df['pyxis'] = df['pyxis'].fillna(\"The patient did not receive any medications.\")\n",
    "df['vitals'] = df['vitals'].fillna(\"The patient had no vitals recorded\")\n",
    "df['codes'] = df['codes'].fillna(\"The patient received no diagnostic codes\")\n",
    "df = df.drop(\"admission\",axis=1)\n",
    "df = df.drop(\"discharge\",axis=1)\n",
    "# df['general'] = df['arrival'] + df['triage'] + df['codes'] + df['pyxis'] \n",
    "# df = df.drop('arrival',axis=1)\n",
    "# df = df.drop('triage',axis=1)\n",
    "# df = df.drop('codes',axis=1)\n",
    "# df = df.drop('pyxis',axis=1)\n",
    "df = df[[col for col in df.columns if col != 'eddischarge'] + ['eddischarge']] # rearrange column to the end\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46742e93-3b05-42e8-a2c0-e693e7d4bac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834.6428571428571\n",
      "982.6333333333333\n",
      "181.45714285714286\n",
      "244.43333333333334\n",
      "278.247619047619\n",
      "180.56190476190477\n"
     ]
    }
   ],
   "source": [
    "print(df.medrecon.str.len().mean())\n",
    "print(df.vitals.str.len().mean())\n",
    "print(df.arrival.str.len().mean())\n",
    "print(df.triage.str.len().mean())\n",
    "print(df.pyxis.str.len().mean())\n",
    "print(df.codes.str.len().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed1dde0-f00c-4198-b2f0-dc15d0776fce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading imagebind weights to .checkpoints/imagebind_huge.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.47G/4.47G [00:14<00:00, 340MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Loading Model\n"
     ]
    }
   ],
   "source": [
    "medrecon_list = df.medrecon.to_list()\n",
    "vitals_list = df.vitals.to_list()\n",
    "arrival_list = df.arrival.to_list()\n",
    "triage_list = df.triage.to_list()\n",
    "pyxis_list = df.pyxis.to_list()\n",
    "codes_list = df.codes.to_list()\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Instantiate model\n",
    "model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "print(\"Done Loading Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fadbe6a-4734-4169-ada2-c7708d3edf9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-8-59e6b344347f&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/imagebind/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">108</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_and_transform_text</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_and_transform_text</span>(text, device):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> text <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>108 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>tokenizer = SimpleTokenizer(bpe_path=BPE_PATH)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109 │   </span>tokens = [tokenizer(t).unsqueeze(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>).to(device) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> t <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> text]                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110 │   </span>tokens = torch.cat(tokens, dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> tokens                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/imagebind/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">multimodal_preprocessors.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">502</span> in       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">499 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.byte_encoder = bytes_to_unicode()                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">500 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.byte_decoder = {v: k <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k, v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.byte_encoder.items()}                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>502 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> g_pathmgr.open(bpe_path, <span style=\"color: #808000; text-decoration-color: #808000\">\"rb\"</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> fh:                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">503 │   │   │   </span>bpe_bytes = io.BytesIO(fh.read())                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">504 │   │   │   </span>merges: List[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>] = gzip.open(bpe_bytes).read().decode(<span style=\"color: #808000; text-decoration-color: #808000\">\"utf-8\"</span>).split(<span style=\"color: #808000; text-decoration-color: #808000\">\"\\n\"</span>)    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">505 │   │   </span>merges = merges[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> : <span style=\"color: #0000ff; text-decoration-color: #0000ff\">49152</span> - <span style=\"color: #0000ff; text-decoration-color: #0000ff\">256</span> - <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/iopath/common/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">file_io.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1062</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">open</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1059 │   │   # pass enable mode to handler that will be logging</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1060 │   │   # read, write operations separately.</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1061 │   │   </span>handler.set_logging(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._enable_logging)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1062 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>bret = handler._open(path, mode, buffering=buffering, **kwargs)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1063 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1064 │   │   </span>kvs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.__get_open_keys(path, mode, buffering)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1065 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.__log_tmetry_keys(handler, kvs)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/iopath/common/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">file_io.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">645</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_open</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">file: a file-like object.</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._check_kwargs(kwargs)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 645 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">open</span>(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 646 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_path_with_cwd(path),                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 647 │   │   │   </span>mode,                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 648 │   │   │   </span>buffering=buffering,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileNotFoundError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> No such file or directory: <span style=\"color: #008000; text-decoration-color: #008000\">'bpe/bpe_simple_vocab_16e6.txt.gz'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-8-59e6b344347f>\u001b[0m:\u001b[94m2\u001b[0m in \u001b[92m<module>\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/imagebind/\u001b[0m\u001b[1;33mdata.py\u001b[0m:\u001b[94m108\u001b[0m in \u001b[92mload_and_transform_text\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m105 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mload_and_transform_text\u001b[0m(text, device):                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m text \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mNone\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m108 \u001b[2m│   \u001b[0mtokenizer = SimpleTokenizer(bpe_path=BPE_PATH)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   \u001b[0mtokens = [tokenizer(t).unsqueeze(\u001b[94m0\u001b[0m).to(device) \u001b[94mfor\u001b[0m t \u001b[95min\u001b[0m text]                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m│   \u001b[0mtokens = torch.cat(tokens, dim=\u001b[94m0\u001b[0m)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m tokens                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/imagebind/models/\u001b[0m\u001b[1;33mmultimodal_preprocessors.py\u001b[0m:\u001b[94m502\u001b[0m in       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__init__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m499 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.byte_encoder = bytes_to_unicode()                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m500 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.byte_decoder = {v: k \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.byte_encoder.items()}                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m501 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m502 \u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m g_pathmgr.open(bpe_path, \u001b[33m\"\u001b[0m\u001b[33mrb\u001b[0m\u001b[33m\"\u001b[0m) \u001b[94mas\u001b[0m fh:                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m503 \u001b[0m\u001b[2m│   │   │   \u001b[0mbpe_bytes = io.BytesIO(fh.read())                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m504 \u001b[0m\u001b[2m│   │   │   \u001b[0mmerges: List[\u001b[96mstr\u001b[0m] = gzip.open(bpe_bytes).read().decode(\u001b[33m\"\u001b[0m\u001b[33mutf-8\u001b[0m\u001b[33m\"\u001b[0m).split(\u001b[33m\"\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\"\u001b[0m)    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m505 \u001b[0m\u001b[2m│   │   \u001b[0mmerges = merges[\u001b[94m1\u001b[0m : \u001b[94m49152\u001b[0m - \u001b[94m256\u001b[0m - \u001b[94m2\u001b[0m + \u001b[94m1\u001b[0m]                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/iopath/common/\u001b[0m\u001b[1;33mfile_io.py\u001b[0m:\u001b[94m1062\u001b[0m in \u001b[92mopen\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1059 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# pass enable mode to handler that will be logging\u001b[0m                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1060 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# read, write operations separately.\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1061 \u001b[0m\u001b[2m│   │   \u001b[0mhandler.set_logging(\u001b[96mself\u001b[0m._enable_logging)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1062 \u001b[2m│   │   \u001b[0mbret = handler._open(path, mode, buffering=buffering, **kwargs)  \u001b[2m# type: ignore\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1063 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1064 \u001b[0m\u001b[2m│   │   \u001b[0mkvs = \u001b[96mself\u001b[0m.__get_open_keys(path, mode, buffering)                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1065 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.__log_tmetry_keys(handler, kvs)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/iopath/common/\u001b[0m\u001b[1;33mfile_io.py\u001b[0m:\u001b[94m645\u001b[0m in \u001b[92m_open\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mfile: a file-like object.\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 643 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._check_kwargs(kwargs)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 645 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mopen\u001b[0m(  \u001b[2m# type: ignore\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 646 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._get_path_with_cwd(path),                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 647 \u001b[0m\u001b[2m│   │   │   \u001b[0mmode,                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 648 \u001b[0m\u001b[2m│   │   │   \u001b[0mbuffering=buffering,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \u001b[32m'bpe/bpe_simple_vocab_16e6.txt.gz'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs_medrecon = {ModalityType.TEXT: data.load_and_transform_text(medrecon_list, device)}\n",
    "    embeddings_medrecon = model(inputs_medrecon)\n",
    "    inputs_vitals = {ModalityType.TEXT: data.load_and_transform_text(vitals_list, device)}\n",
    "    embeddings_vitals = model(inputs_vitals)\n",
    "    inputs_arrival = {ModalityType.TEXT: data.load_and_transform_text(arrival_list, device)}\n",
    "    embeddings_arrival = model(inputs_general)\n",
    "    inputs_triage = {ModalityType.TEXT: data.load_and_transform_text(triage_list, device)}\n",
    "    embeddings_triage = model(inputs_general)\n",
    "    inputs_pyxis = {ModalityType.TEXT: data.load_and_transform_text(pyxis_list, device)}\n",
    "    embeddings_pyxis = model(inputs_general)\n",
    "    inputs_codes = {ModalityType.TEXT: data.load_and_transform_text(codes_list, device)}\n",
    "    embeddings_codes = model(inputs_general)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a9cc1-d7d8-4f9f-994e-3e1eb69ec571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings_medrecon = model(inputs_medrecon)\n",
    "    embeddings_vitals = model(inputs_vitals)\n",
    "    embeddings_arrival = model(inputs_arrival)\n",
    "    embeddings_triage = model(inputs_triage)\n",
    "    embeddings_pyxis = model(inputs_pyxis)\n",
    "    embeddings_codes = model(inputs_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1686860a-b5b3-4293-b8ab-947a44a90121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = torch.eq(embeddings_medrecon['text'], embeddings_arrival['text'])\n",
    "f.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2bcda3-d651-4a8b-9984-59508558b5df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = torch.eq(embeddings_vitals['text'], embeddings_triage['text'])\n",
    "f.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfac3fb-f89c-40da-9f2a-357a8a024b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = torch.eq(embeddings_codes['text'], embeddings_medrecon['text'])\n",
    "f.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6112a-7faf-4367-bcfa-d0ca2858fc4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ff0cd-6142-44b9-b2f8-9b297616ddb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(embeddings_arrival['text'].size())\n",
    "print(embeddings_vitals['text'].size())\n",
    "print(embeddings_medrecon['text'].size())\n",
    "print(embeddings_codes['text'].size())\n",
    "print(embeddings_pyxis['text'].size())\n",
    "print(embeddings_triage['text'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9cf16-63df-4213-ae5b-fb0baf639b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concatenate vectors into one\n",
    "concat = torch.cat((embeddings_vitals['text'], embeddings_arrival['text'], embeddings_medrecon['text'], embeddings_codes['text'],embeddings_pyxis['text'], embeddings_triage['text']), -1)\n",
    "print(concat.size())\n",
    "concat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff3903-3b3b-413e-a55b-e0da858e10c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        queries = self.query(x)\n",
    "        keys = self.key(x)\n",
    "        values = self.value(x)\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / (self.input_dim ** 0.5)\n",
    "        attention = self.softmax(scores)\n",
    "        weighted = torch.bmm(attention, values)\n",
    "        return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f4a67-b63c-49da-a015-00dbdb7e4ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self_attention = SelfAttention( 6144 )\n",
    "output = self_attention(concat.unsqueeze(0))\n",
    "output = output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ea088-7dd5-4dc9-9e28-f66cb0b0d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a dense layer to project them on different space.\n",
    "dense_layer = nn.Linear(6144, 768)\n",
    "new_vec = dense_layer(concat)\n",
    "print(new_vec.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa288f41-fd98-4f98-90c5-aea587d1c28d",
   "metadata": {},
   "source": [
    "# TODO: What do I do with the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82265fc-38f2-4893-b8cd-9681e26b9a39",
   "metadata": {},
   "source": [
    "# Need a way to update gradients, and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1276cb9-f217-42d4-aa73-a223dc698d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn our tensor and match it with the label. After doing so, we feed it through a training loop to identify.\n",
    "\n",
    "import torch\n",
    "\n",
    "def create_dataset(dataset, lookback):\n",
    "    \"\"\"Transform a time series into a prediction dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset: A numpy array of time series, first dimension is the time steps\n",
    "        lookback: Size of window for prediction\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-lookback):\n",
    "        feature = dataset[i:i+lookback]\n",
    "        target = dataset[i+1:i+lookback+1]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "X_train, y_train = create_dataset(train, lookback=lookback)\n",
    "X_test, y_test = create_dataset(test, lookback=lookback)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Output:\n",
    "# torch.Size([95, 1, 1]) torch.Size([95, 1, 1])\n",
    "# torch.Size([47, 1, 1]) torch.Size([47, 1, 1])\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
