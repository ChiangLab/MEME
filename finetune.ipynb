{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cdfe9b-3248-4257-8777-320411a5083e",
   "metadata": {},
   "source": [
    "# Notebook that handles fine-tuning from start to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2d0d69-8883-460f-9d43-ed584c3b8628",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-15w0hyf3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-15w0hyf3\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 1982dd3b15867c46e1c20645901b0de469fd935f\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (1.23.5)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (4.64.1)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0.dev0) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.32.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.32.0.dev0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.32.0.dev0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.32.0.dev0) (3.4)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.32.0.dev0-py3-none-any.whl size=7522589 sha256=52234025dd643f813e9c18edd0a9217c7577c3157be7c58b03c5607a967dbac9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xiqhzz2q/wheels/f7/92/8c/752ff3bfcd3439805d8bbf641614da38ef3226e127ebea86ee\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, safetensors, regex, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.12.2 huggingface-hub-0.16.4 regex-2023.8.8 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.32.0.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07af796-a411-4f95-970c-66d4bc16d139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker>=2.140.0\n",
      "  Using cached sagemaker-2.178.0-py2.py3-none-any.whl\n",
      "Collecting transformers==4.26.1\n",
      "  Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "Collecting datasets[s3]==2.10.1\n",
      "  Using cached datasets-2.10.1-py3-none-any.whl (469 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (23.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (2023.8.8)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26.1) (1.23.5)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (2023.1.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (0.3.6)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (11.0.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (0.70.14)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (1.5.3)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.9/site-packages (from datasets[s3]==2.10.1) (0.4.2)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (4.13.0)\n",
      "Collecting attrs<24,>=23.1.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (3.20.2)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (0.7.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (0.3.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "Collecting boto3<2.0,>=1.26.131\n",
      "  Using cached boto3-1.28.30-py3-none-any.whl (135 kB)\n",
      "Collecting jsonschema\n",
      "  Using cached jsonschema-4.19.0-py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (0.2.0)\n",
      "Collecting platformdirs\n",
      "  Using cached platformdirs-3.10.0-py3-none-any.whl (17 kB)\n",
      "Collecting tblib==1.7.0\n",
      "  Using cached tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (1.0.1)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker>=2.140.0) (2.2.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.131->sagemaker>=2.140.0) (0.6.0)\n",
      "Collecting botocore<1.32.0,>=1.31.30\n",
      "  Using cached botocore-1.31.30-py3-none-any.whl (11.1 MB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.131->sagemaker>=2.140.0) (1.0.1)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets[s3]==2.10.1) (2.1.1)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker>=2.140.0) (3.13.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.26.1) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.26.1) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.26.1) (3.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from google-pasta->sagemaker>=2.140.0) (1.16.0)\n",
      "Collecting referencing>=0.28.4\n",
      "  Using cached referencing-0.30.2-py3-none-any.whl (25 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Using cached rpds_py-0.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets[s3]==2.10.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets[s3]==2.10.1) (2022.7.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker>=2.140.0) (1.7.6.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker>=2.140.0) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.9/site-packages (from schema->sagemaker>=2.140.0) (21.6.0)\n",
      "Installing collected packages: xxhash, tblib, rpds-py, pyyaml, platformdirs, multidict, frozenlist, attrs, async-timeout, yarl, responses, referencing, botocore, aiosignal, transformers, jsonschema-specifications, aiohttp, jsonschema, boto3, sagemaker, datasets\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.2.0\n",
      "    Uninstalling attrs-22.2.0:\n",
      "      Successfully uninstalled attrs-22.2.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.70\n",
      "    Uninstalling botocore-1.29.70:\n",
      "      Successfully uninstalled botocore-1.29.70\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.32.0.dev0\n",
      "    Uninstalling transformers-4.32.0.dev0:\n",
      "      Successfully uninstalled transformers-4.32.0.dev0\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.70\n",
      "    Uninstalling boto3-1.26.70:\n",
      "      Successfully uninstalled boto3-1.26.70\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.132.0\n",
      "    Uninstalling sagemaker-2.132.0:\n",
      "      Successfully uninstalled sagemaker-2.132.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.70 requires botocore==1.29.70, but you have botocore 1.31.30 which is incompatible.\n",
      "awscli 1.27.70 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 boto3-1.28.30 botocore-1.31.30 datasets-2.10.1 frozenlist-1.4.0 jsonschema-4.19.0 jsonschema-specifications-2023.7.1 multidict-6.0.4 platformdirs-3.10.0 pyyaml-6.0.1 referencing-0.30.2 responses-0.18.0 rpds-py-0.9.2 sagemaker-2.178.0 tblib-1.7.0 transformers-4.26.1 xxhash-3.3.0 yarl-1.9.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sagemaker>=2.140.0\" \"transformers==4.26.1\" \"datasets[s3]==2.10.1\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47093608-4b6c-449e-a46d-b8ad1b470ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==0.20.3\n",
      "  Using cached accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from accelerate==0.20.3) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from accelerate==0.20.3) (23.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from accelerate==0.20.3) (1.13.1+cu117)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from accelerate==0.20.3) (5.9.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from accelerate==0.20.3) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->accelerate==0.20.3) (4.4.0)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.16.0\n",
      "    Uninstalling accelerate-0.16.0:\n",
      "      Successfully uninstalled accelerate-0.16.0\n",
      "Successfully installed accelerate-0.20.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate==0.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f73ef536-b378-41a3-81ae-322c59b7057c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO # Python 3.\n",
    "from datasets import load_dataset,Dataset,DatasetDict,concatenate_datasets\n",
    "\n",
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#from models.EDdisposition import EDdispositionClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "df9b6b67-a221-49e0-b124-a17632c5d259",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders:\n",
      "mimic-iv-2.2/\n",
      "mimic-iv-clinical-database-demo-2.2/\n",
      "mimic-iv-ed-2.2/\n",
      "mimic-iv-ed-demo-2.2/\n"
     ]
    }
   ],
   "source": [
    "# reads out files\n",
    "\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('chianglab-dataderivatives')\n",
    "\n",
    "folders = set()\n",
    "\n",
    "for obj in bucket.objects.all():\n",
    "    prefix, delimiter, _ = obj.key.rpartition('/')\n",
    "    if prefix:\n",
    "        folders.add(prefix + '/')\n",
    "\n",
    "print('Folders:')\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dd74a89c-ea6b-4550-9887-4a94a8eff1dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mimic-iv-ed-demo-2.2/\n",
      "mimic-iv-ed-demo-2.2/text_repr.json\n",
      "['', '']\n"
     ]
    }
   ],
   "source": [
    "bucket = 'chianglab-dataderivatives'\n",
    "subfolder = 'mimic-iv-ed-demo-2.2/'\n",
    "conn = boto3.client('s3')\n",
    "contents = conn.list_objects(Bucket=bucket, Prefix=subfolder)['Contents']\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for f in contents:\n",
    "    print(f['Key'])\n",
    "    file_list.append(f['Key'][36:])\n",
    "\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e4b9c0-ee03-4c21-842c-6535b5ba9bf8",
   "metadata": {},
   "source": [
    "### Load in Data and reformat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "27b8dcdf-d676-4c66-bad0-a5849d3d8705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'chianglab-dataderivatives'\n",
    "file_path = \"mimic-iv-clinical-database-demo-2.2/admissions_text.json\"\n",
    "\n",
    "\n",
    "content_object = s3.Object(bucket_name, file_path)\n",
    "file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file_content)\n",
    "\n",
    "df = pd.DataFrame(list(json_content.items()), columns = ['ID', 'ad_headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "70dd7fc7-f2b6-4d70-9dff-e9d549d58579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add codes \n",
    "\n",
    "bucket_name = 'chianglab-dataderivatives'\n",
    "file_path = \"mimic-iv-clinical-database-demo-2.2/codes_text.json\"\n",
    "\n",
    "\n",
    "content_object = s3.Object(bucket_name, file_path)\n",
    "file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file_content)\n",
    "df['codes_headline'] = df['ID'].map(json_content)\n",
    "\n",
    "# add meds\n",
    "bucket_name = 'chianglab-dataderivatives'\n",
    "file_path = \"mimic-iv-clinical-database-demo-2.2/meds_text.json\"\n",
    "\n",
    "content_object = s3.Object(bucket_name, file_path)\n",
    "file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file_content)\n",
    "df['meds_headline'] = df['ID'].map(json_content)\n",
    "\n",
    "# add labs\n",
    "bucket_name = 'chianglab-dataderivatives'\n",
    "file_path = \"mimic-iv-clinical-database-demo-2.2/labs_text.json\"\n",
    "\n",
    "content_object = s3.Object(bucket_name, file_path)\n",
    "file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file_content)\n",
    "# need to change float IDs to int but then back to a string to map\n",
    "res = dict()\n",
    "for key in json_content:\n",
    "    res[str(int(float(key)))] = json_content[key]\n",
    "    \n",
    "df['labs_headline'] = df['ID'].map(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552fe514-9801-427b-a41c-a1147cf11d8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data we will be working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "93ea2dc7-0f30-4c0e-8bf1-164023eff1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataframe: 210\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival</th>\n",
       "      <th>eddischarge</th>\n",
       "      <th>admission</th>\n",
       "      <th>discharge</th>\n",
       "      <th>triage</th>\n",
       "      <th>medrecon</th>\n",
       "      <th>vitals</th>\n",
       "      <th>pyxis</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37887480</th>\n",
       "      <td>Patient 10014729, a 21 year old white - other ...</td>\n",
       "      <td>The ED disposition was admitted at 2125-03-19 ...</td>\n",
       "      <td>The patient was admitted at 2125-03-19 16:58:00.</td>\n",
       "      <td>The patient's discharge disposition was: home ...</td>\n",
       "      <td>At triage: temperature was 99.1, pulse was 90....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2125-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34176810</th>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>The ED disposition was admitted at 2154-02-05 ...</td>\n",
       "      <td>The patient was admitted at 2154-02-05 21:58:00.</td>\n",
       "      <td>The patient's discharge disposition was: home ...</td>\n",
       "      <td>At triage: temperature was 97.7, pulse was 74....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103106</th>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>The ED disposition was home at 2154-08-03 22:2...</td>\n",
       "      <td>The patient was not admitted.</td>\n",
       "      <td>The patient was not admitted.</td>\n",
       "      <td>At triage: temperature was 96.2, pulse was 74....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38797992</th>\n",
       "      <td>Patient 10020640, a 91 year old white female, ...</td>\n",
       "      <td>The ED disposition was admitted at 2153-02-13 ...</td>\n",
       "      <td>The patient was admitted at 2153-02-13 00:22:00.</td>\n",
       "      <td>The patient's discharge disposition was: skill...</td>\n",
       "      <td>At triage: temperature was 99.2, pulse was 130...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2153-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33473053</th>\n",
       "      <td>Patient 10015272, a 78 year old white female, ...</td>\n",
       "      <td>The ED disposition was admitted at 2137-06-12 ...</td>\n",
       "      <td>The patient was admitted at 2137-06-12 18:36:00.</td>\n",
       "      <td>The patient's discharge disposition was: home ...</td>\n",
       "      <td>At triage: temperature was 97.5, pulse was 118...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2137-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arrival  \\\n",
       "37887480  Patient 10014729, a 21 year old white - other ...   \n",
       "34176810  Patient 10018328, a 83 year old white female, ...   \n",
       "32103106  Patient 10018328, a 83 year old white female, ...   \n",
       "38797992  Patient 10020640, a 91 year old white female, ...   \n",
       "33473053  Patient 10015272, a 78 year old white female, ...   \n",
       "\n",
       "                                                eddischarge  \\\n",
       "37887480  The ED disposition was admitted at 2125-03-19 ...   \n",
       "34176810  The ED disposition was admitted at 2154-02-05 ...   \n",
       "32103106  The ED disposition was home at 2154-08-03 22:2...   \n",
       "38797992  The ED disposition was admitted at 2153-02-13 ...   \n",
       "33473053  The ED disposition was admitted at 2137-06-12 ...   \n",
       "\n",
       "                                                 admission  \\\n",
       "37887480  The patient was admitted at 2125-03-19 16:58:00.   \n",
       "34176810  The patient was admitted at 2154-02-05 21:58:00.   \n",
       "32103106                     The patient was not admitted.   \n",
       "38797992  The patient was admitted at 2153-02-13 00:22:00.   \n",
       "33473053  The patient was admitted at 2137-06-12 18:36:00.   \n",
       "\n",
       "                                                  discharge  \\\n",
       "37887480  The patient's discharge disposition was: home ...   \n",
       "34176810  The patient's discharge disposition was: home ...   \n",
       "32103106                      The patient was not admitted.   \n",
       "38797992  The patient's discharge disposition was: skill...   \n",
       "33473053  The patient's discharge disposition was: home ...   \n",
       "\n",
       "                                                     triage  \\\n",
       "37887480  At triage: temperature was 99.1, pulse was 90....   \n",
       "34176810  At triage: temperature was 97.7, pulse was 74....   \n",
       "32103106  At triage: temperature was 96.2, pulse was 74....   \n",
       "38797992  At triage: temperature was 99.2, pulse was 130...   \n",
       "33473053  At triage: temperature was 97.5, pulse was 118...   \n",
       "\n",
       "                                                   medrecon  \\\n",
       "37887480  The patient was previously taking the followin...   \n",
       "34176810  The patient was previously taking the followin...   \n",
       "32103106  The patient was previously taking the followin...   \n",
       "38797992  The patient was previously taking the followin...   \n",
       "33473053  The patient was previously taking the followin...   \n",
       "\n",
       "                                                     vitals  \\\n",
       "37887480  The patient had the following vitals: At 2125-...   \n",
       "34176810  The patient had the following vitals: At 2154-...   \n",
       "32103106  The patient had the following vitals: At 2154-...   \n",
       "38797992  The patient had the following vitals: At 2153-...   \n",
       "33473053  The patient had the following vitals: At 2137-...   \n",
       "\n",
       "                                                      pyxis  \\\n",
       "37887480  The patient received the following medications...   \n",
       "34176810                                                NaN   \n",
       "32103106  The patient received the following medications...   \n",
       "38797992  The patient received the following medications...   \n",
       "33473053  The patient received the following medications...   \n",
       "\n",
       "                                                      codes  \n",
       "37887480  The patient received the following diagnostic ...  \n",
       "34176810  The patient received the following diagnostic ...  \n",
       "32103106  The patient received the following diagnostic ...  \n",
       "38797992  The patient received the following diagnostic ...  \n",
       "33473053  The patient received the following diagnostic ...  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = 'chianglab-dataderivatives'\n",
    "file_path = \"mimic-iv-ed-demo-2.2/text_repr.json\"\n",
    "\n",
    "\n",
    "content_object = s3.Object(bucket_name, file_path)\n",
    "file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file_content)\n",
    "df = pd.DataFrame(json_content).T\n",
    "print(\"length of dataframe: \"+ str(len(df)))\n",
    "df.head(5)\n",
    "# df['codes_headline'] = df['ID'].map(json_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cc4b0f90-7596-4d53-8334-8bb0c6695f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival</th>\n",
       "      <th>eddischarge</th>\n",
       "      <th>triage</th>\n",
       "      <th>medrecon</th>\n",
       "      <th>vitals</th>\n",
       "      <th>pyxis</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37887480</th>\n",
       "      <td>Patient 10014729, a 21 year old white - other ...</td>\n",
       "      <td>1</td>\n",
       "      <td>At triage: temperature was 99.1, pulse was 90....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2125-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34176810</th>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>At triage: temperature was 97.7, pulse was 74....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>The patient did not receive any medications.</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103106</th>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>At triage: temperature was 96.2, pulse was 74....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38797992</th>\n",
       "      <td>Patient 10020640, a 91 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>At triage: temperature was 99.2, pulse was 130...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2153-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33473053</th>\n",
       "      <td>Patient 10015272, a 78 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>At triage: temperature was 97.5, pulse was 118...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2137-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30272878</th>\n",
       "      <td>Patient 10038999, a 45 year old white male, ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>At triage: temperature was not recorded, pulse...</td>\n",
       "      <td>The patient was previously not taking any medi...</td>\n",
       "      <td>The patient had the following vitals: At 2131-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31628990</th>\n",
       "      <td>Patient 10009049, a 56 year old white male, ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>At triage: temperature was 99.0, pulse was 87....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2174-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32405286</th>\n",
       "      <td>Patient 10004457, a 65 year old white male, ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>At triage: temperature was 97.6, pulse was 103...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2141-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34391979</th>\n",
       "      <td>Patient 10004720, a 61 year old white male, ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>At triage: temperature was not recorded, pulse...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2186-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34161260</th>\n",
       "      <td>Patient 10004720, a 61 year old white male, ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>At triage: temperature was 97.0, pulse was 106...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2183-...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arrival  eddischarge  \\\n",
       "37887480  Patient 10014729, a 21 year old white - other ...            1   \n",
       "34176810  Patient 10018328, a 83 year old white female, ...            1   \n",
       "32103106  Patient 10018328, a 83 year old white female, ...            0   \n",
       "38797992  Patient 10020640, a 91 year old white female, ...            1   \n",
       "33473053  Patient 10015272, a 78 year old white female, ...            1   \n",
       "...                                                     ...          ...   \n",
       "30272878  Patient 10038999, a 45 year old white male, ar...            1   \n",
       "31628990  Patient 10009049, a 56 year old white male, ar...            1   \n",
       "32405286  Patient 10004457, a 65 year old white male, ar...            1   \n",
       "34391979  Patient 10004720, a 61 year old white male, ar...            1   \n",
       "34161260  Patient 10004720, a 61 year old white male, ar...            0   \n",
       "\n",
       "                                                     triage  \\\n",
       "37887480  At triage: temperature was 99.1, pulse was 90....   \n",
       "34176810  At triage: temperature was 97.7, pulse was 74....   \n",
       "32103106  At triage: temperature was 96.2, pulse was 74....   \n",
       "38797992  At triage: temperature was 99.2, pulse was 130...   \n",
       "33473053  At triage: temperature was 97.5, pulse was 118...   \n",
       "...                                                     ...   \n",
       "30272878  At triage: temperature was not recorded, pulse...   \n",
       "31628990  At triage: temperature was 99.0, pulse was 87....   \n",
       "32405286  At triage: temperature was 97.6, pulse was 103...   \n",
       "34391979  At triage: temperature was not recorded, pulse...   \n",
       "34161260  At triage: temperature was 97.0, pulse was 106...   \n",
       "\n",
       "                                                   medrecon  \\\n",
       "37887480  The patient was previously taking the followin...   \n",
       "34176810  The patient was previously taking the followin...   \n",
       "32103106  The patient was previously taking the followin...   \n",
       "38797992  The patient was previously taking the followin...   \n",
       "33473053  The patient was previously taking the followin...   \n",
       "...                                                     ...   \n",
       "30272878  The patient was previously not taking any medi...   \n",
       "31628990  The patient was previously taking the followin...   \n",
       "32405286  The patient was previously taking the followin...   \n",
       "34391979  The patient was previously taking the followin...   \n",
       "34161260  The patient was previously taking the followin...   \n",
       "\n",
       "                                                     vitals  \\\n",
       "37887480  The patient had the following vitals: At 2125-...   \n",
       "34176810  The patient had the following vitals: At 2154-...   \n",
       "32103106  The patient had the following vitals: At 2154-...   \n",
       "38797992  The patient had the following vitals: At 2153-...   \n",
       "33473053  The patient had the following vitals: At 2137-...   \n",
       "...                                                     ...   \n",
       "30272878  The patient had the following vitals: At 2131-...   \n",
       "31628990  The patient had the following vitals: At 2174-...   \n",
       "32405286  The patient had the following vitals: At 2141-...   \n",
       "34391979  The patient had the following vitals: At 2186-...   \n",
       "34161260  The patient had the following vitals: At 2183-...   \n",
       "\n",
       "                                                      pyxis  \\\n",
       "37887480  The patient received the following medications...   \n",
       "34176810       The patient did not receive any medications.   \n",
       "32103106  The patient received the following medications...   \n",
       "38797992  The patient received the following medications...   \n",
       "33473053  The patient received the following medications...   \n",
       "...                                                     ...   \n",
       "30272878  The patient received the following medications...   \n",
       "31628990  The patient received the following medications...   \n",
       "32405286  The patient received the following medications...   \n",
       "34391979  The patient received the following medications...   \n",
       "34161260  The patient received the following medications...   \n",
       "\n",
       "                                                      codes  \n",
       "37887480  The patient received the following diagnostic ...  \n",
       "34176810  The patient received the following diagnostic ...  \n",
       "32103106  The patient received the following diagnostic ...  \n",
       "38797992  The patient received the following diagnostic ...  \n",
       "33473053  The patient received the following diagnostic ...  \n",
       "...                                                     ...  \n",
       "30272878  The patient received the following diagnostic ...  \n",
       "31628990  The patient received the following diagnostic ...  \n",
       "32405286  The patient received the following diagnostic ...  \n",
       "34391979  The patient received the following diagnostic ...  \n",
       "34161260  The patient received the following diagnostic ...  \n",
       "\n",
       "[210 rows x 7 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['eddischarge'] = [1 if 'admitted' in s.lower() else 0 for s in df['eddischarge']] # admitted = 1, Home = 0\n",
    "df['medrecon'] = df['medrecon'].fillna(\"The patient was previously not taking any medications.\")\n",
    "df['pyxis'] = df['pyxis'].fillna(\"The patient did not receive any medications.\")\n",
    "df['vitals'] = df['vitals'].fillna(\"The patient had no vitals recorded\")\n",
    "df['codes'] = df['codes'].fillna(\"The patient received no diagnostic codes\")\n",
    "df = df.drop(\"admission\",axis=1)\n",
    "df = df.drop(\"discharge\",axis=1)\n",
    "df\n",
    "\n",
    "# remove admission and discharge columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f3a9732f-750c-4fd6-b434-1a650cb0329c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medrecon</th>\n",
       "      <th>vitals</th>\n",
       "      <th>general</th>\n",
       "      <th>eddischarge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37887480</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2125-...</td>\n",
       "      <td>Patient 10014729, a 21 year old white - other ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34176810</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103106</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38797992</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2153-...</td>\n",
       "      <td>Patient 10020640, a 91 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33473053</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2137-...</td>\n",
       "      <td>Patient 10015272, a 78 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30272878</th>\n",
       "      <td>The patient was previously not taking any medi...</td>\n",
       "      <td>The patient had the following vitals: At 2131-...</td>\n",
       "      <td>Patient 10038999, a 45 year old white male, ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31628990</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2174-...</td>\n",
       "      <td>Patient 10009049, a 56 year old white male, ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32405286</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2141-...</td>\n",
       "      <td>Patient 10004457, a 65 year old white male, ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34391979</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2186-...</td>\n",
       "      <td>Patient 10004720, a 61 year old white male, ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34161260</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2183-...</td>\n",
       "      <td>Patient 10004720, a 61 year old white male, ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   medrecon  \\\n",
       "37887480  The patient was previously taking the followin...   \n",
       "34176810  The patient was previously taking the followin...   \n",
       "32103106  The patient was previously taking the followin...   \n",
       "38797992  The patient was previously taking the followin...   \n",
       "33473053  The patient was previously taking the followin...   \n",
       "...                                                     ...   \n",
       "30272878  The patient was previously not taking any medi...   \n",
       "31628990  The patient was previously taking the followin...   \n",
       "32405286  The patient was previously taking the followin...   \n",
       "34391979  The patient was previously taking the followin...   \n",
       "34161260  The patient was previously taking the followin...   \n",
       "\n",
       "                                                     vitals  \\\n",
       "37887480  The patient had the following vitals: At 2125-...   \n",
       "34176810  The patient had the following vitals: At 2154-...   \n",
       "32103106  The patient had the following vitals: At 2154-...   \n",
       "38797992  The patient had the following vitals: At 2153-...   \n",
       "33473053  The patient had the following vitals: At 2137-...   \n",
       "...                                                     ...   \n",
       "30272878  The patient had the following vitals: At 2131-...   \n",
       "31628990  The patient had the following vitals: At 2174-...   \n",
       "32405286  The patient had the following vitals: At 2141-...   \n",
       "34391979  The patient had the following vitals: At 2186-...   \n",
       "34161260  The patient had the following vitals: At 2183-...   \n",
       "\n",
       "                                                    general  eddischarge  \n",
       "37887480  Patient 10014729, a 21 year old white - other ...            1  \n",
       "34176810  Patient 10018328, a 83 year old white female, ...            1  \n",
       "32103106  Patient 10018328, a 83 year old white female, ...            0  \n",
       "38797992  Patient 10020640, a 91 year old white female, ...            1  \n",
       "33473053  Patient 10015272, a 78 year old white female, ...            1  \n",
       "...                                                     ...          ...  \n",
       "30272878  Patient 10038999, a 45 year old white male, ar...            1  \n",
       "31628990  Patient 10009049, a 56 year old white male, ar...            1  \n",
       "32405286  Patient 10004457, a 65 year old white male, ar...            1  \n",
       "34391979  Patient 10004720, a 61 year old white male, ar...            1  \n",
       "34161260  Patient 10004720, a 61 year old white male, ar...            0  \n",
       "\n",
       "[210 rows x 4 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['general'] = df['arrival'] + df['triage'] + df['codes'] + df['pyxis'] \n",
    "df = df.drop('arrival',axis=1)\n",
    "df = df.drop('triage',axis=1)\n",
    "df = df.drop('codes',axis=1)\n",
    "df = df.drop('pyxis',axis=1)\n",
    "df = df[[col for col in df.columns if col != 'eddischarge'] + ['eddischarge']] # rearrange column to the end\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0b390118-36e6-494b-849a-e34fb4b3d8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split dataframe here\n",
    "def train_validate_test_split(df, train_percent=.8, validate_percent=.1, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    df = df.reset_index()\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    train = train.set_index('index')\n",
    "    validate = validate.set_index('index')\n",
    "    test = test.set_index('index')\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5a163469-b787-4577-81f8-126e8c258769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 21 21\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = train_validate_test_split(df)\n",
    "print(len(train), len(validate), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "130c6e47-d7d4-4702-8f0d-346b8bb3071c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medrecon</th>\n",
       "      <th>vitals</th>\n",
       "      <th>general</th>\n",
       "      <th>eddischarge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31023359</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2149-...</td>\n",
       "      <td>Patient 10005866, a 57 year old portuguese mal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38213541</th>\n",
       "      <td>The patient was previously not taking any medi...</td>\n",
       "      <td>The patient had the following vitals: At 2116-...</td>\n",
       "      <td>Patient 10017492, a 84 year old patient declin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   medrecon  \\\n",
       "index                                                         \n",
       "31023359  The patient was previously taking the followin...   \n",
       "38213541  The patient was previously not taking any medi...   \n",
       "\n",
       "                                                     vitals  \\\n",
       "index                                                         \n",
       "31023359  The patient had the following vitals: At 2149-...   \n",
       "38213541  The patient had the following vitals: At 2116-...   \n",
       "\n",
       "                                                    general  eddischarge  \n",
       "index                                                                     \n",
       "31023359  Patient 10005866, a 57 year old portuguese mal...            0  \n",
       "38213541  Patient 10017492, a 84 year old patient declin...            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medrecon</th>\n",
       "      <th>vitals</th>\n",
       "      <th>general</th>\n",
       "      <th>eddischarge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34176810</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2154-...</td>\n",
       "      <td>Patient 10018328, a 83 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37330786</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2115-...</td>\n",
       "      <td>Patient 10035631, a 63 year old white male, ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   medrecon  \\\n",
       "index                                                         \n",
       "34176810  The patient was previously taking the followin...   \n",
       "37330786  The patient was previously taking the followin...   \n",
       "\n",
       "                                                     vitals  \\\n",
       "index                                                         \n",
       "34176810  The patient had the following vitals: At 2154-...   \n",
       "37330786  The patient had the following vitals: At 2115-...   \n",
       "\n",
       "                                                    general  eddischarge  \n",
       "index                                                                     \n",
       "34176810  Patient 10018328, a 83 year old white female, ...            1  \n",
       "37330786  Patient 10035631, a 63 year old white male, ar...            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medrecon</th>\n",
       "      <th>vitals</th>\n",
       "      <th>general</th>\n",
       "      <th>eddischarge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35933027</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2176-...</td>\n",
       "      <td>Patient 10012853, a 91 year old black/african ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32287800</th>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2147-...</td>\n",
       "      <td>Patient 10014354, a 60 year old white male, ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   medrecon  \\\n",
       "index                                                         \n",
       "35933027  The patient was previously taking the followin...   \n",
       "32287800  The patient was previously taking the followin...   \n",
       "\n",
       "                                                     vitals  \\\n",
       "index                                                         \n",
       "35933027  The patient had the following vitals: At 2176-...   \n",
       "32287800  The patient had the following vitals: At 2147-...   \n",
       "\n",
       "                                                    general  eddischarge  \n",
       "index                                                                     \n",
       "35933027  Patient 10012853, a 91 year old black/african ...            0  \n",
       "32287800  Patient 10014354, a 60 year old white male, ar...            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head(2))\n",
    "display(validate.head(2))\n",
    "display(test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6fe4bf1e-7ce3-436c-bc4c-ca73fa9682dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cut(df, type):\n",
    "    col_names = df.columns.drop(\"eddischarge\")\n",
    "    l = []\n",
    "    for i in col_names:\n",
    "        temp = df[[i, 'eddischarge']].reset_index()\n",
    "        temp = temp.sort_values(by=['index']).reset_index() # we sort the patient ID numerically before dropping it to preserve order in encoding\n",
    "        temp = temp.drop(columns=[\"index\", \"level_0\"])\n",
    "        temp = temp.rename(columns={i: \"headline\", \"eddischarge\": \"label\"})\n",
    "        l.append(temp)\n",
    "        print(\"\\\"\"+i+ \"\\\" Dataframe:\", type, \"set\")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ea1ad58f-03a0-496b-b8d5-9869f4ad22c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"medrecon\" Dataframe: train set\n",
      "\"vitals\" Dataframe: train set\n",
      "\"general\" Dataframe: train set\n",
      "\"medrecon\" Dataframe: validate set\n",
      "\"vitals\" Dataframe: validate set\n",
      "\"general\" Dataframe: validate set\n",
      "\"medrecon\" Dataframe: test set\n",
      "\"vitals\" Dataframe: test set\n",
      "\"general\" Dataframe: test set\n"
     ]
    }
   ],
   "source": [
    "l1 = cut(train, \"train\")\n",
    "l2 = cut(validate, \"validate\")\n",
    "l3 = cut (test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b6195e5e-6d2e-4ee5-bee4-e29db198b112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Indices for sub-dataframes, that will each individually be tokenized\n",
    "# 0 - arrival\n",
    "# 1 - admission\n",
    "# 2 - discharge\n",
    "# 3 - triage\n",
    "# 4 - medrecon\n",
    "# 5 - vitals\n",
    "# 6 - pyxis\n",
    "# 7 - codes\n",
    "class preprocess():\n",
    "\n",
    "    def tokenize(self,batch):\n",
    "      return tokenizer(batch[\"headline\"], truncation=True, max_length=512)\n",
    "\n",
    "    def convert(self, l):\n",
    "        \"\"\"\n",
    "        Run this method\n",
    "        \"\"\"\n",
    "        medrecon_hf=Dataset.from_pandas(l[0])\n",
    "        vitals_hf=Dataset.from_pandas(l[1])\n",
    "        general_hf=Dataset.from_pandas(l[2])\n",
    "\n",
    "        tokenized_medrecon = medrecon_hf.map(tokenize, batched=True)\n",
    "        tokenized_vitals = vitals_hf.map(tokenize, batched=True)\n",
    "        tokenized_general = general_hf.map(tokenize, batched=True)\n",
    "        \n",
    "        dataset_cc = concatenate_datasets([tokenized_medrecon, tokenized_vitals, tokenized_general])\n",
    "        print(\"Specs:\")\n",
    "        print(dataset_cc)\n",
    "        return dataset_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b808e7e8-77f0-4bda-a431-25fa019b0bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map:   0%|          | 0/168 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                   \u001b[A\n",
      "Map:   0%|          | 0/168 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                   \u001b[A\n",
      "Map:   0%|          | 0/168 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                   \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specs:\n",
      "Dataset({\n",
      "    features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 504\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map:   0%|          | 0/21 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                  \u001b[A\n",
      "Map:   0%|          | 0/21 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                  \u001b[A\n",
      "Map:   0%|          | 0/21 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specs:\n",
      "Dataset({\n",
      "    features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 63\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map:   0%|          | 0/21 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                  \u001b[A\n",
      "Map:   0%|          | 0/21 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                  \u001b[A\n",
      "Map:   0%|          | 0/21 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specs:\n",
      "Dataset({\n",
      "    features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 63\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# grabs a tokenizer from the distilbert-base-uncased model\n",
    "model = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "tokenizer.model_max_len=512\n",
    "\n",
    "# calls methods and tokenizes text\n",
    "processor = preprocess()\n",
    "train = processor.convert(l1)\n",
    "validate = processor.convert(l2)\n",
    "test = processor.convert(l3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "77eff688-4dee-41d5-b9eb-7e54e873e8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 504\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"label\"] )\n",
    "validate.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"label\"] )\n",
    "test.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"label\"] )\n",
    "print(train)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "176b7539-896a-47b1-966a-3ca46ba2cab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_cc = DatasetDict({\n",
    "    'train': train,\n",
    "    'test': test,\n",
    "    'valid': validate})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2edcbcb1-5786-44e8-846d-f52227abcea0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 504\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 63\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 63\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "12d71491-ebae-4c70-aa07-fde98de378ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EDdispositionClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    A task-specific custom transformer model for predicting ED Disposition. \n",
    "    This model loads a pre-trained transformer model and adds a new dropout \n",
    "    and linear layer at the end for fine-tuning and prediction on specific tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, checkpoint, num_labels ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            checkpoint (str): The name of the pre-trained model or path to the model weights.\n",
    "            num_labels (int): The number of output labels in the final classification layer.\n",
    "        \"\"\"\n",
    "        super(EDdispositionClassifier, self).__init__()\n",
    "        self.num_labels = num_labels # number of labels for classifier\n",
    "        \n",
    "        # checkpoint is the model name \n",
    "        self.model = model = AutoModel.from_pretrained(checkpoint, config = AutoConfig.from_pretrained(checkpoint, \n",
    "                                                                                                       output_attention = True, \n",
    "                                                                                                       output_hidden_state = True ) )\n",
    "        # New Layer\n",
    "        self.dropout = nn.Dropout(0.1) # to prevent overfittting\n",
    "        self.classifier = nn.Linear(768, num_labels) #FC Layer - takes in a 768 token vector and is a Linear classifier with n labels\n",
    "        \n",
    "    def forward(self, input_ids = None, attention_mask=None, labels = None ):\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "        \n",
    "        Args:\n",
    "            input_ids (torch.Tensor, optional): Tensor of input IDs. Defaults to None.\n",
    "            attention_mask (torch.Tensor, optional): Tensor for attention masks. Defaults to None.\n",
    "            labels (torch.Tensor, optional): Tensor for labels. Defaults to None.\n",
    "            \n",
    "        Returns:\n",
    "            TokenClassifierOutput: A named tuple with the following fields:\n",
    "            - loss (torch.FloatTensor of shape (1,), optional, returned when label_ids is provided) – Classification loss.\n",
    "            - logits (torch.FloatTensor of shape (batch_size, num_labels)) – Classification scores before SoftMax.\n",
    "            - hidden_states (tuple(torch.FloatTensor), optional, returned when output_hidden_states=True is passed or when config.output_hidden_states=True) – Tuple of torch.FloatTensor (one for the output of the embeddings + one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).\n",
    "            - attentions (tuple(torch.FloatTensor), optional, returned when output_attentions=True is passed or when config.output_attentions=True) – Tuple of torch.FloatTensor (one for each layer) of shape (batch_size, num_heads, sequence_length, sequence_length).\n",
    "        \"\"\"\n",
    "        # calls on the Automodel to deploy correct model - in our case distilled-bert-uncased\n",
    "        outputs = self.model(input_ids = input_ids, attention_mask = attention_mask  )\n",
    "        \n",
    "        # retrieves the last hidden state\n",
    "        last_hidden_state = outputs[0]\n",
    "        \n",
    "        # include dropout from constructor to feed forward network\n",
    "        sequence_outputs = self.dropout(last_hidden_state)\n",
    "        \n",
    "        # finally add linear layer from input\n",
    "        logits = self.classifier(sequence_outputs[:, 0, : ].view(-1, 768 ))\n",
    "        \n",
    "        # calculates loss \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_func = nn.CrossEntropyLoss() # Change this if it becomes more than binary classification\n",
    "            loss = loss_func(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            \n",
    "            # TokenClassifierOutput - returns predicted label\n",
    "            return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "000d7cb4-13cf-47e2-b200-a0d7d6b60c75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset_cc['train'], shuffle = True, batch_size = 8, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    dataset_cc['valid'], shuffle = True, collate_fn = data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3abfa248-9faa-4798-b0d1-17c5b5c044c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_task_specific = EDdispositionClassifier(checkpoint=model, num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f6cfc1d4-d637-40d4-8f72-da9191b20403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "optimizer = AdamW(model_task_specific.parameters(), lr = 5e-5 )\n",
    "\n",
    "num_epoch = 5\n",
    "\n",
    "num_training_steps = num_epoch * len(train_dataloader)\n",
    "print(len(train_dataloader))\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "14d113f3-ed24-43ed-b43b-e6c1cfc84b38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"f1\", \"precision\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cb186332-7510-4cbb-8e7d-ddef0cde8bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 504/504 [1:47:35<00:00, 12.81s/it]\n",
      "\n",
      "\n",
      "510it [1:47:35, 12.66s/it]:00<?, ?it/s]\u001b[A\u001b[A\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\n",
      "  0%|          | 1/315 [00:02<10:32,  2.02s/it]\u001b[A\n",
      "  1%|          | 2/315 [00:04<12:00,  2.30s/it]\u001b[A\n",
      "  1%|          | 3/315 [00:07<12:31,  2.41s/it]\u001b[A\n",
      "  1%|▏         | 4/315 [00:08<10:24,  2.01s/it]\u001b[A\n",
      "  2%|▏         | 5/315 [00:10<11:01,  2.13s/it]\u001b[A\n",
      "  2%|▏         | 6/315 [00:12<10:01,  1.95s/it]\u001b[A\n",
      "  2%|▏         | 7/315 [00:14<10:57,  2.14s/it]\u001b[A\n",
      "  3%|▎         | 8/315 [00:17<11:30,  2.25s/it]\u001b[A\n",
      "  3%|▎         | 9/315 [00:19<11:46,  2.31s/it]\u001b[A\n",
      "  3%|▎         | 10/315 [00:21<10:49,  2.13s/it]\u001b[A\n",
      "  3%|▎         | 11/315 [00:22<08:59,  1.77s/it]\u001b[A\n",
      "  4%|▍         | 12/315 [00:24<09:53,  1.96s/it]\u001b[A\n",
      "  4%|▍         | 13/315 [00:26<08:59,  1.78s/it]\u001b[A\n",
      "  4%|▍         | 14/315 [00:28<09:44,  1.94s/it]\u001b[A\n",
      "  5%|▍         | 15/315 [00:31<10:34,  2.12s/it]\u001b[A\n",
      "  5%|▌         | 16/315 [00:33<10:48,  2.17s/it]\u001b[A\n",
      "  5%|▌         | 17/315 [00:35<09:54,  2.00s/it]\u001b[A\n",
      "  6%|▌         | 18/315 [00:37<10:31,  2.13s/it]\u001b[A\n",
      "  6%|▌         | 19/315 [00:39<11:00,  2.23s/it]\u001b[A\n",
      "  6%|▋         | 20/315 [00:42<11:03,  2.25s/it]\u001b[A\n",
      "  7%|▋         | 21/315 [00:44<11:29,  2.35s/it]\u001b[A\n",
      "  7%|▋         | 22/315 [00:46<10:25,  2.13s/it]\u001b[A\n",
      "  7%|▋         | 23/315 [00:48<10:48,  2.22s/it]\u001b[A\n",
      "  8%|▊         | 24/315 [00:50<09:17,  1.92s/it]\u001b[A\n",
      "  8%|▊         | 25/315 [00:52<10:00,  2.07s/it]\u001b[A\n",
      "  8%|▊         | 26/315 [00:53<08:49,  1.83s/it]\u001b[A\n",
      "  9%|▊         | 27/315 [00:56<09:31,  1.99s/it]\u001b[A\n",
      "  9%|▉         | 28/315 [00:57<08:37,  1.80s/it]\u001b[A\n",
      "  9%|▉         | 29/315 [00:59<09:35,  2.01s/it]\u001b[A\n",
      " 10%|▉         | 30/315 [01:01<09:21,  1.97s/it]\u001b[A\n",
      " 10%|▉         | 31/315 [01:04<09:57,  2.10s/it]\u001b[A\n",
      " 10%|█         | 32/315 [01:06<10:29,  2.22s/it]\u001b[A\n",
      " 10%|█         | 33/315 [01:09<10:41,  2.28s/it]\u001b[A\n",
      " 11%|█         | 34/315 [01:11<10:55,  2.33s/it]\u001b[A\n",
      " 11%|█         | 35/315 [01:14<11:06,  2.38s/it]\u001b[A\n",
      " 11%|█▏        | 36/315 [01:15<10:01,  2.15s/it]\u001b[A\n",
      " 12%|█▏        | 37/315 [01:18<10:13,  2.21s/it]\u001b[A\n",
      " 12%|█▏        | 38/315 [01:20<10:36,  2.30s/it]\u001b[A\n",
      " 12%|█▏        | 39/315 [01:22<10:31,  2.29s/it]\u001b[A\n",
      " 13%|█▎        | 40/315 [01:24<10:09,  2.22s/it]\u001b[A\n",
      " 13%|█▎        | 41/315 [01:27<10:27,  2.29s/it]\u001b[A\n",
      " 13%|█▎        | 42/315 [01:29<09:36,  2.11s/it]\u001b[A\n",
      " 14%|█▎        | 43/315 [01:31<09:56,  2.19s/it]\u001b[A\n",
      " 14%|█▍        | 44/315 [01:33<10:17,  2.28s/it]\u001b[A\n",
      " 14%|█▍        | 45/315 [01:36<10:21,  2.30s/it]\u001b[A\n",
      " 15%|█▍        | 46/315 [01:38<10:27,  2.33s/it]\u001b[A\n",
      " 15%|█▍        | 47/315 [01:40<09:20,  2.09s/it]\u001b[A\n",
      " 15%|█▌        | 48/315 [01:41<07:55,  1.78s/it]\u001b[A\n",
      " 16%|█▌        | 49/315 [01:43<08:42,  1.96s/it]\u001b[A\n",
      " 16%|█▌        | 50/315 [01:46<09:38,  2.18s/it]\u001b[A\n",
      " 16%|█▌        | 51/315 [01:48<09:52,  2.24s/it]\u001b[A\n",
      " 17%|█▋        | 52/315 [01:51<10:02,  2.29s/it]\u001b[A\n",
      " 17%|█▋        | 53/315 [01:53<10:03,  2.30s/it]\u001b[A\n",
      " 17%|█▋        | 54/315 [01:55<10:08,  2.33s/it]\u001b[A\n",
      " 17%|█▋        | 55/315 [01:58<10:09,  2.34s/it]\u001b[A\n",
      " 18%|█▊        | 56/315 [02:00<10:12,  2.36s/it]\u001b[A\n",
      " 18%|█▊        | 57/315 [02:03<10:12,  2.37s/it]\u001b[A\n",
      " 18%|█▊        | 58/315 [02:05<10:15,  2.39s/it]\u001b[A\n",
      " 19%|█▊        | 59/315 [02:07<10:11,  2.39s/it]\u001b[A\n",
      " 19%|█▉        | 60/315 [02:09<09:13,  2.17s/it]\u001b[A\n",
      " 19%|█▉        | 61/315 [02:10<08:06,  1.91s/it]\u001b[A\n",
      " 20%|█▉        | 62/315 [02:13<08:26,  2.00s/it]\u001b[A\n",
      " 20%|██        | 63/315 [02:15<08:56,  2.13s/it]\u001b[A\n",
      "\n",
      "  0%|          | 1/315 [02:15<11:49:42, 135.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 4/315 [02:15<2:13:11, 25.70s/it]  \u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7/315 [02:15<1:01:14, 11.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 10/315 [02:16<34:26,  6.77s/it] \u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 14/315 [02:16<18:41,  3.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 17/315 [02:16<12:32,  2.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 20/315 [02:16<08:32,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 23/315 [02:16<05:52,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 26/315 [02:16<04:05,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 29/315 [02:16<02:52,  1.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 32/315 [02:16<02:01,  2.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 35/315 [02:17<01:27,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 38/315 [02:17<01:04,  4.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 41/315 [02:17<00:49,  5.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 44/315 [02:17<00:39,  6.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 47/315 [02:17<00:30,  8.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 50/315 [02:17<00:25, 10.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 52/315 [02:18<00:23, 11.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 55/315 [02:18<00:18, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 58/315 [02:18<00:15, 16.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 61/315 [02:18<00:15, 16.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 64/315 [02:20<12:36,  3.01s/it]\u001b[A\n",
      " 21%|██        | 65/315 [02:21<10:10,  2.44s/it]\u001b[A\n",
      " 21%|██        | 66/315 [02:23<08:53,  2.14s/it]\u001b[A\n",
      " 21%|██▏       | 67/315 [02:25<08:54,  2.16s/it]\u001b[A\n",
      " 22%|██▏       | 68/315 [02:27<08:23,  2.04s/it]\u001b[A\n",
      " 22%|██▏       | 69/315 [02:29<08:51,  2.16s/it]\u001b[A\n",
      " 22%|██▏       | 70/315 [02:31<09:10,  2.25s/it]\u001b[A\n",
      " 23%|██▎       | 71/315 [02:32<07:28,  1.84s/it]\u001b[A\n",
      " 23%|██▎       | 72/315 [02:34<06:49,  1.69s/it]\u001b[A\n",
      "\n",
      " 20%|██        | 63/315 [02:36<00:15, 16.51it/s]\u001b[A\u001b[A\n",
      " 23%|██▎       | 73/315 [02:36<07:30,  1.86s/it]\u001b[A\n",
      " 23%|██▎       | 74/315 [02:38<07:45,  1.93s/it]\u001b[A\n",
      " 24%|██▍       | 75/315 [02:40<08:17,  2.07s/it]\u001b[A\n",
      " 24%|██▍       | 76/315 [02:43<08:37,  2.16s/it]\u001b[A\n",
      " 24%|██▍       | 77/315 [02:45<08:46,  2.21s/it]\u001b[A\n",
      " 25%|██▍       | 78/315 [02:48<09:12,  2.33s/it]\u001b[A\n",
      " 25%|██▌       | 79/315 [02:49<08:10,  2.08s/it]\u001b[A\n",
      " 25%|██▌       | 80/315 [02:52<08:22,  2.14s/it]\u001b[A\n",
      " 26%|██▌       | 81/315 [02:54<08:22,  2.15s/it]\u001b[A\n",
      " 26%|██▌       | 82/315 [02:56<08:35,  2.21s/it]\u001b[A\n",
      " 26%|██▋       | 83/315 [02:59<08:53,  2.30s/it]\u001b[A\n",
      " 27%|██▋       | 84/315 [03:01<09:07,  2.37s/it]\u001b[A\n",
      " 27%|██▋       | 85/315 [03:04<09:08,  2.39s/it]\u001b[A\n",
      " 27%|██▋       | 86/315 [03:06<09:15,  2.43s/it]\u001b[A\n",
      " 28%|██▊       | 87/315 [03:09<09:18,  2.45s/it]\u001b[A\n",
      " 28%|██▊       | 88/315 [03:11<09:15,  2.45s/it]\u001b[A\n",
      " 28%|██▊       | 89/315 [03:12<07:27,  1.98s/it]\u001b[A\n",
      " 29%|██▊       | 90/315 [03:14<07:51,  2.09s/it]\u001b[A\n",
      " 29%|██▉       | 91/315 [03:17<08:13,  2.20s/it]\u001b[A\n",
      " 29%|██▉       | 92/315 [03:19<08:17,  2.23s/it]\u001b[A\n",
      " 30%|██▉       | 93/315 [03:21<07:33,  2.04s/it]\u001b[A\n",
      " 30%|██▉       | 94/315 [03:23<07:55,  2.15s/it]\u001b[A\n",
      " 30%|███       | 95/315 [03:25<08:15,  2.25s/it]\u001b[A\n",
      " 30%|███       | 96/315 [03:27<07:33,  2.07s/it]\u001b[A\n",
      " 31%|███       | 97/315 [03:29<07:46,  2.14s/it]\u001b[A\n",
      " 31%|███       | 98/315 [03:32<08:04,  2.23s/it]\u001b[A\n",
      " 31%|███▏      | 99/315 [03:34<08:04,  2.24s/it]\u001b[A\n",
      " 32%|███▏      | 100/315 [03:35<06:42,  1.87s/it]\u001b[A\n",
      " 32%|███▏      | 101/315 [03:36<05:56,  1.67s/it]\u001b[A\n",
      " 32%|███▏      | 102/315 [03:38<05:51,  1.65s/it]\u001b[A\n",
      " 33%|███▎      | 103/315 [03:40<06:45,  1.91s/it]\u001b[A\n",
      " 33%|███▎      | 104/315 [03:43<07:23,  2.10s/it]\u001b[A\n",
      " 33%|███▎      | 105/315 [03:45<06:49,  1.95s/it]\u001b[A\n",
      " 34%|███▎      | 106/315 [03:47<07:15,  2.09s/it]\u001b[A\n",
      " 34%|███▍      | 107/315 [03:49<07:38,  2.21s/it]\u001b[A\n",
      " 34%|███▍      | 108/315 [03:52<07:48,  2.26s/it]\u001b[A\n",
      " 35%|███▍      | 109/315 [03:54<07:42,  2.25s/it]\u001b[A\n",
      " 35%|███▍      | 110/315 [03:57<07:52,  2.30s/it]\u001b[A\n",
      " 35%|███▌      | 111/315 [03:59<08:04,  2.37s/it]\u001b[A\n",
      " 36%|███▌      | 112/315 [04:01<08:02,  2.38s/it]\u001b[A\n",
      " 36%|███▌      | 113/315 [04:04<08:06,  2.41s/it]\u001b[A\n",
      " 36%|███▌      | 114/315 [04:06<07:33,  2.26s/it]\u001b[A\n",
      " 37%|███▋      | 115/315 [04:08<07:43,  2.32s/it]\u001b[A\n",
      " 37%|███▋      | 116/315 [04:10<06:36,  1.99s/it]\u001b[A\n",
      " 37%|███▋      | 117/315 [04:12<07:03,  2.14s/it]\u001b[A\n",
      " 37%|███▋      | 118/315 [04:14<06:49,  2.08s/it]\u001b[A\n",
      " 38%|███▊      | 119/315 [04:16<06:16,  1.92s/it]\u001b[A\n",
      " 38%|███▊      | 120/315 [04:18<06:49,  2.10s/it]\u001b[A\n",
      " 38%|███▊      | 121/315 [04:21<07:10,  2.22s/it]\u001b[A\n",
      " 39%|███▊      | 122/315 [04:23<07:16,  2.26s/it]\u001b[A\n",
      " 39%|███▉      | 123/315 [04:25<07:24,  2.32s/it]\u001b[A\n",
      " 39%|███▉      | 124/315 [04:28<07:20,  2.31s/it]\u001b[A\n",
      " 40%|███▉      | 125/315 [04:30<07:25,  2.34s/it]\u001b[A\n",
      " 40%|████      | 126/315 [04:32<07:26,  2.36s/it]\u001b[A\n",
      "\n",
      " 20%|██        | 64/315 [04:33<57:52, 13.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 66/315 [04:33<44:27, 10.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 69/315 [04:33<29:39,  7.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 72/315 [04:33<20:02,  4.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 74/315 [04:33<15:17,  3.81s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 78/315 [04:33<09:05,  2.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 81/315 [04:33<06:20,  1.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 84/315 [04:34<04:26,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 87/315 [04:34<03:07,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 90/315 [04:34<02:13,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 93/315 [04:34<01:34,  2.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 96/315 [04:34<01:07,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 99/315 [04:34<00:50,  4.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 102/315 [04:34<00:37,  5.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 105/315 [04:34<00:28,  7.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 108/315 [04:35<00:23,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 111/315 [04:35<00:18, 10.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 114/315 [04:35<00:16, 12.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 117/315 [04:35<00:14, 13.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 120/315 [04:35<00:12, 15.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 123/315 [04:35<00:11, 16.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 126/315 [04:36<00:11, 16.71it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8484848484848484}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 127/315 [04:38<10:16,  3.28s/it]\u001b[A\n",
      " 41%|████      | 128/315 [04:40<09:22,  3.01s/it]\u001b[A\n",
      " 41%|████      | 129/315 [04:43<08:45,  2.83s/it]\u001b[A\n",
      " 41%|████▏     | 130/315 [04:44<07:39,  2.48s/it]\u001b[A\n",
      "\n",
      " 40%|████      | 126/315 [04:46<00:11, 16.71it/s]\u001b[A\u001b[A\n",
      " 42%|████▏     | 131/315 [04:47<07:30,  2.45s/it]\u001b[A\n",
      " 42%|████▏     | 132/315 [04:49<07:27,  2.44s/it]\u001b[A\n",
      " 42%|████▏     | 133/315 [04:51<06:54,  2.28s/it]\u001b[A\n",
      " 43%|████▎     | 134/315 [04:53<06:52,  2.28s/it]\u001b[A\n",
      " 43%|████▎     | 135/315 [04:54<05:43,  1.91s/it]\u001b[A\n",
      " 43%|████▎     | 136/315 [04:57<06:08,  2.06s/it]\u001b[A\n",
      " 43%|████▎     | 137/315 [04:59<06:29,  2.19s/it]\u001b[A\n",
      " 44%|████▍     | 138/315 [05:01<05:44,  1.95s/it]\u001b[A\n",
      " 44%|████▍     | 139/315 [05:02<05:25,  1.85s/it]\u001b[A\n",
      " 44%|████▍     | 140/315 [05:03<04:44,  1.63s/it]\u001b[A\n",
      " 45%|████▍     | 141/315 [05:06<05:20,  1.84s/it]\u001b[A\n",
      " 45%|████▌     | 142/315 [05:08<05:51,  2.03s/it]\u001b[A\n",
      " 45%|████▌     | 143/315 [05:11<06:09,  2.15s/it]\u001b[A\n",
      " 46%|████▌     | 144/315 [05:13<06:19,  2.22s/it]\u001b[A\n",
      " 46%|████▌     | 145/315 [05:15<06:03,  2.14s/it]\u001b[A\n",
      " 46%|████▋     | 146/315 [05:17<06:13,  2.21s/it]\u001b[A\n",
      " 47%|████▋     | 147/315 [05:20<06:20,  2.26s/it]\u001b[A\n",
      " 47%|████▋     | 148/315 [05:22<06:18,  2.27s/it]\u001b[A\n",
      " 47%|████▋     | 149/315 [05:24<06:26,  2.33s/it]\u001b[A\n",
      " 48%|████▊     | 150/315 [05:27<06:25,  2.34s/it]\u001b[A\n",
      " 48%|████▊     | 151/315 [05:29<06:27,  2.36s/it]\u001b[A\n",
      " 48%|████▊     | 152/315 [05:30<05:18,  1.96s/it]\u001b[A\n",
      " 49%|████▊     | 153/315 [05:33<05:39,  2.10s/it]\u001b[A\n",
      " 49%|████▉     | 154/315 [05:35<05:54,  2.20s/it]\u001b[A\n",
      " 49%|████▉     | 155/315 [05:38<06:02,  2.27s/it]\u001b[A\n",
      " 50%|████▉     | 156/315 [05:40<06:07,  2.31s/it]\u001b[A\n",
      " 50%|████▉     | 157/315 [05:42<06:14,  2.37s/it]\u001b[A\n",
      " 50%|█████     | 158/315 [05:45<06:18,  2.41s/it]\u001b[A\n",
      " 50%|█████     | 159/315 [05:47<06:16,  2.41s/it]\u001b[A\n",
      " 51%|█████     | 160/315 [05:49<05:58,  2.31s/it]\u001b[A\n",
      " 51%|█████     | 161/315 [05:52<05:58,  2.33s/it]\u001b[A\n",
      " 51%|█████▏    | 162/315 [05:54<06:01,  2.36s/it]\u001b[A\n",
      " 52%|█████▏    | 163/315 [05:57<05:59,  2.37s/it]\u001b[A\n",
      " 52%|█████▏    | 164/315 [05:59<05:57,  2.37s/it]\u001b[A\n",
      " 52%|█████▏    | 165/315 [06:01<05:50,  2.34s/it]\u001b[A\n",
      " 53%|█████▎    | 166/315 [06:02<04:48,  1.93s/it]\u001b[A\n",
      " 53%|█████▎    | 167/315 [06:04<04:29,  1.82s/it]\u001b[A\n",
      " 53%|█████▎    | 168/315 [06:06<04:53,  2.00s/it]\u001b[A\n",
      " 54%|█████▎    | 169/315 [06:08<04:34,  1.88s/it]\u001b[A\n",
      " 54%|█████▍    | 170/315 [06:10<04:57,  2.05s/it]\u001b[A\n",
      " 54%|█████▍    | 171/315 [06:12<04:32,  1.89s/it]\u001b[A\n",
      " 55%|█████▍    | 172/315 [06:14<04:51,  2.04s/it]\u001b[A\n",
      " 55%|█████▍    | 173/315 [06:15<04:02,  1.71s/it]\u001b[A\n",
      " 55%|█████▌    | 174/315 [06:16<03:45,  1.60s/it]\u001b[A\n",
      " 56%|█████▌    | 175/315 [06:19<04:13,  1.81s/it]\u001b[A\n",
      " 56%|█████▌    | 176/315 [06:21<04:38,  2.00s/it]\u001b[A\n",
      " 56%|█████▌    | 177/315 [06:23<04:47,  2.08s/it]\u001b[A\n",
      " 57%|█████▋    | 178/315 [06:26<04:59,  2.18s/it]\u001b[A\n",
      " 57%|█████▋    | 179/315 [06:28<04:35,  2.03s/it]\u001b[A\n",
      " 57%|█████▋    | 180/315 [06:29<04:18,  1.91s/it]\u001b[A\n",
      " 57%|█████▋    | 181/315 [06:32<04:33,  2.04s/it]\u001b[A\n",
      " 58%|█████▊    | 182/315 [06:34<04:46,  2.16s/it]\u001b[A\n",
      " 58%|█████▊    | 183/315 [06:36<04:53,  2.22s/it]\u001b[A\n",
      " 58%|█████▊    | 184/315 [06:39<04:57,  2.27s/it]\u001b[A\n",
      " 59%|█████▊    | 185/315 [06:41<04:55,  2.27s/it]\u001b[A\n",
      " 59%|█████▉    | 186/315 [06:43<04:56,  2.30s/it]\u001b[A\n",
      " 59%|█████▉    | 187/315 [06:45<04:18,  2.02s/it]\u001b[A\n",
      " 60%|█████▉    | 188/315 [06:46<03:54,  1.85s/it]\u001b[A\n",
      " 60%|██████    | 189/315 [06:48<04:07,  1.96s/it]\u001b[A\n",
      "\n",
      " 40%|████      | 127/315 [06:48<52:13, 16.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 129/315 [06:49<38:06, 12.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 133/315 [06:49<21:20,  7.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 136/315 [06:49<14:25,  4.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 139/315 [06:49<09:49,  3.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 142/315 [06:49<06:44,  2.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 145/315 [06:49<04:39,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 149/315 [06:50<02:54,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 152/315 [06:50<02:05,  1.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 155/315 [06:50<01:29,  1.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 158/315 [06:50<01:05,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 160/315 [06:50<00:52,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 163/315 [06:50<00:36,  4.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 166/315 [06:50<00:27,  5.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 168/315 [06:51<00:23,  6.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 171/315 [06:51<00:17,  8.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 174/315 [06:51<00:13, 10.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 177/315 [06:51<00:10, 13.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 180/315 [06:51<00:08, 15.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 183/315 [06:51<00:07, 16.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 186/315 [06:51<00:08, 15.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 189/315 [06:52<00:08, 15.08it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8484848484848484}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 190/315 [06:54<06:29,  3.12s/it]\u001b[A\n",
      " 61%|██████    | 191/315 [06:55<05:07,  2.48s/it]\u001b[A\n",
      " 61%|██████    | 192/315 [06:57<04:33,  2.22s/it]\u001b[A\n",
      " 61%|██████▏   | 193/315 [06:59<04:30,  2.22s/it]\u001b[A\n",
      " 62%|██████▏   | 194/315 [07:01<04:33,  2.26s/it]\u001b[A\n",
      " 62%|██████▏   | 195/315 [07:04<04:36,  2.30s/it]\u001b[A\n",
      "\n",
      " 60%|██████    | 189/315 [07:06<00:08, 15.08it/s]\u001b[A\u001b[A\n",
      " 62%|██████▏   | 196/315 [07:06<04:35,  2.32s/it]\u001b[A\n",
      " 63%|██████▎   | 197/315 [07:09<04:36,  2.35s/it]\u001b[A\n",
      " 63%|██████▎   | 198/315 [07:10<04:06,  2.11s/it]\u001b[A\n",
      " 63%|██████▎   | 199/315 [07:12<04:13,  2.19s/it]\u001b[A\n",
      " 63%|██████▎   | 200/315 [07:15<04:16,  2.23s/it]\u001b[A\n",
      " 64%|██████▍   | 201/315 [07:17<03:57,  2.08s/it]\u001b[A\n",
      " 64%|██████▍   | 202/315 [07:19<04:02,  2.15s/it]\u001b[A\n",
      " 64%|██████▍   | 203/315 [07:20<03:32,  1.90s/it]\u001b[A\n",
      " 65%|██████▍   | 204/315 [07:22<03:43,  2.02s/it]\u001b[A\n",
      " 65%|██████▌   | 205/315 [07:24<03:33,  1.94s/it]\u001b[A\n",
      " 65%|██████▌   | 206/315 [07:27<03:46,  2.08s/it]\u001b[A\n",
      " 66%|██████▌   | 207/315 [07:29<03:53,  2.16s/it]\u001b[A\n",
      " 66%|██████▌   | 208/315 [07:31<03:44,  2.10s/it]\u001b[A\n",
      " 66%|██████▋   | 209/315 [07:32<03:16,  1.86s/it]\u001b[A\n",
      " 67%|██████▋   | 210/315 [07:34<03:26,  1.96s/it]\u001b[A\n",
      " 67%|██████▋   | 211/315 [07:37<03:38,  2.10s/it]\u001b[A\n",
      " 67%|██████▋   | 212/315 [07:38<03:19,  1.94s/it]\u001b[A\n",
      " 68%|██████▊   | 213/315 [07:41<03:24,  2.00s/it]\u001b[A\n",
      " 68%|██████▊   | 214/315 [07:43<03:33,  2.11s/it]\u001b[A\n",
      " 68%|██████▊   | 215/315 [07:44<03:08,  1.88s/it]\u001b[A\n",
      " 69%|██████▊   | 216/315 [07:47<03:17,  1.99s/it]\u001b[A\n",
      " 69%|██████▉   | 217/315 [07:48<02:57,  1.81s/it]\u001b[A\n",
      " 69%|██████▉   | 218/315 [07:50<03:11,  1.97s/it]\u001b[A\n",
      " 70%|██████▉   | 219/315 [07:52<03:07,  1.95s/it]\u001b[A\n",
      " 70%|██████▉   | 220/315 [07:55<03:17,  2.08s/it]\u001b[A\n",
      " 70%|███████   | 221/315 [07:57<03:28,  2.21s/it]\u001b[A\n",
      " 70%|███████   | 222/315 [07:58<02:48,  1.82s/it]\u001b[A\n",
      " 71%|███████   | 223/315 [08:00<03:01,  1.98s/it]\u001b[A\n",
      " 71%|███████   | 224/315 [08:02<02:51,  1.88s/it]\u001b[A\n",
      " 71%|███████▏  | 225/315 [08:04<02:59,  1.99s/it]\u001b[A\n",
      " 72%|███████▏  | 226/315 [08:07<03:12,  2.16s/it]\u001b[A\n",
      " 72%|███████▏  | 227/315 [08:09<03:14,  2.21s/it]\u001b[A\n",
      " 72%|███████▏  | 228/315 [08:11<03:14,  2.23s/it]\u001b[A\n",
      " 73%|███████▎  | 229/315 [08:14<03:14,  2.27s/it]\u001b[A\n",
      " 73%|███████▎  | 230/315 [08:16<03:14,  2.29s/it]\u001b[A\n",
      " 73%|███████▎  | 231/315 [08:18<03:14,  2.31s/it]\u001b[A\n",
      " 74%|███████▎  | 232/315 [08:21<03:14,  2.35s/it]\u001b[A\n",
      " 74%|███████▍  | 233/315 [08:23<03:14,  2.38s/it]\u001b[A\n",
      " 74%|███████▍  | 234/315 [08:25<03:05,  2.29s/it]\u001b[A\n",
      " 75%|███████▍  | 235/315 [08:27<02:49,  2.12s/it]\u001b[A\n",
      " 75%|███████▍  | 236/315 [08:29<02:51,  2.17s/it]\u001b[A\n",
      " 75%|███████▌  | 237/315 [08:32<02:53,  2.22s/it]\u001b[A\n",
      " 76%|███████▌  | 238/315 [08:34<02:55,  2.28s/it]\u001b[A\n",
      " 76%|███████▌  | 239/315 [08:37<02:55,  2.31s/it]\u001b[A\n",
      " 76%|███████▌  | 240/315 [08:39<02:54,  2.32s/it]\u001b[A\n",
      " 77%|███████▋  | 241/315 [08:41<02:39,  2.15s/it]\u001b[A\n",
      " 77%|███████▋  | 242/315 [08:43<02:40,  2.19s/it]\u001b[A\n",
      " 77%|███████▋  | 243/315 [08:45<02:24,  2.01s/it]\u001b[A\n",
      " 77%|███████▋  | 244/315 [08:47<02:28,  2.09s/it]\u001b[A\n",
      " 78%|███████▊  | 245/315 [08:48<02:14,  1.91s/it]\u001b[A\n",
      " 78%|███████▊  | 246/315 [08:51<02:19,  2.02s/it]\u001b[A\n",
      " 78%|███████▊  | 247/315 [08:53<02:25,  2.14s/it]\u001b[A\n",
      " 79%|███████▊  | 248/315 [08:54<02:05,  1.87s/it]\u001b[A\n",
      " 79%|███████▉  | 249/315 [08:57<02:15,  2.05s/it]\u001b[A\n",
      " 79%|███████▉  | 250/315 [08:59<02:20,  2.16s/it]\u001b[A\n",
      " 80%|███████▉  | 251/315 [09:02<02:22,  2.22s/it]\u001b[A\n",
      " 80%|████████  | 252/315 [09:04<02:23,  2.28s/it]\u001b[A\n",
      "\n",
      " 60%|██████    | 190/315 [09:04<34:56, 16.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 191/315 [09:04<29:24, 14.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 193/315 [09:04<20:10,  9.93s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 196/315 [09:04<11:57,  6.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 199/315 [09:05<07:29,  3.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 202/315 [09:05<04:50,  2.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 205/315 [09:05<03:11,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 208/315 [09:05<02:09,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 211/315 [09:05<01:27,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 214/315 [09:05<01:00,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 217/315 [09:05<00:42,  2.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 220/315 [09:06<00:30,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 223/315 [09:06<00:21,  4.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 226/315 [09:06<00:15,  5.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 229/315 [09:06<00:11,  7.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 233/315 [09:06<00:08,  9.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 236/315 [09:06<00:06, 11.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 239/315 [09:06<00:05, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 242/315 [09:07<00:04, 14.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 245/315 [09:07<00:04, 15.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 248/315 [09:07<00:03, 17.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 251/315 [09:07<00:03, 17.96it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8484848484848484}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 253/315 [09:09<03:19,  3.22s/it]\u001b[A\n",
      " 81%|████████  | 254/315 [09:12<03:00,  2.96s/it]\u001b[A\n",
      " 81%|████████  | 255/315 [09:14<02:41,  2.70s/it]\u001b[A\n",
      " 81%|████████▏ | 256/315 [09:16<02:35,  2.63s/it]\u001b[A\n",
      " 82%|████████▏ | 257/315 [09:18<02:22,  2.46s/it]\u001b[A\n",
      " 82%|████████▏ | 258/315 [09:20<02:04,  2.18s/it]\u001b[A\n",
      " 82%|████████▏ | 259/315 [09:22<02:06,  2.25s/it]\u001b[A\n",
      " 83%|████████▎ | 260/315 [09:23<01:41,  1.85s/it]\u001b[A\n",
      " 83%|████████▎ | 261/315 [09:26<01:49,  2.03s/it]\u001b[A\n",
      "\n",
      " 80%|████████  | 252/315 [09:26<00:03, 17.96it/s]\u001b[A\u001b[A\n",
      " 83%|████████▎ | 262/315 [09:28<01:51,  2.10s/it]\u001b[A\n",
      " 83%|████████▎ | 263/315 [09:30<01:54,  2.19s/it]\u001b[A\n",
      " 84%|████████▍ | 264/315 [09:33<01:53,  2.23s/it]\u001b[A\n",
      " 84%|████████▍ | 265/315 [09:35<01:51,  2.24s/it]\u001b[A\n",
      " 84%|████████▍ | 266/315 [09:37<01:51,  2.28s/it]\u001b[A\n",
      " 85%|████████▍ | 267/315 [09:38<01:34,  1.96s/it]\u001b[A\n",
      " 85%|████████▌ | 268/315 [09:40<01:24,  1.81s/it]\u001b[A\n",
      " 85%|████████▌ | 269/315 [09:42<01:25,  1.87s/it]\u001b[A\n",
      " 86%|████████▌ | 270/315 [09:44<01:31,  2.03s/it]\u001b[A\n",
      " 86%|████████▌ | 271/315 [09:47<01:33,  2.12s/it]\u001b[A\n",
      " 86%|████████▋ | 272/315 [09:49<01:31,  2.12s/it]\u001b[A\n",
      " 87%|████████▋ | 273/315 [09:51<01:30,  2.16s/it]\u001b[A\n",
      " 87%|████████▋ | 274/315 [09:53<01:22,  2.01s/it]\u001b[A\n",
      " 87%|████████▋ | 275/315 [09:55<01:24,  2.11s/it]\u001b[A\n",
      " 88%|████████▊ | 276/315 [09:57<01:25,  2.19s/it]\u001b[A\n",
      " 88%|████████▊ | 277/315 [10:00<01:27,  2.29s/it]\u001b[A\n",
      " 88%|████████▊ | 278/315 [10:02<01:25,  2.32s/it]\u001b[A\n",
      " 89%|████████▊ | 279/315 [10:05<01:24,  2.34s/it]\u001b[A\n",
      " 89%|████████▉ | 280/315 [10:07<01:23,  2.38s/it]\u001b[A\n",
      " 89%|████████▉ | 281/315 [10:09<01:20,  2.36s/it]\u001b[A\n",
      " 90%|████████▉ | 282/315 [10:12<01:18,  2.39s/it]\u001b[A\n",
      " 90%|████████▉ | 283/315 [10:14<01:16,  2.38s/it]\u001b[A\n",
      " 90%|█████████ | 284/315 [10:17<01:13,  2.38s/it]\u001b[A\n",
      " 90%|█████████ | 285/315 [10:18<01:01,  2.04s/it]\u001b[A\n",
      " 91%|█████████ | 286/315 [10:20<01:01,  2.13s/it]\u001b[A\n",
      " 91%|█████████ | 287/315 [10:23<01:01,  2.19s/it]\u001b[A\n",
      " 91%|█████████▏| 288/315 [10:24<00:54,  2.03s/it]\u001b[A\n",
      " 92%|█████████▏| 289/315 [10:27<00:55,  2.13s/it]\u001b[A\n",
      " 92%|█████████▏| 290/315 [10:29<00:55,  2.20s/it]\u001b[A\n",
      " 92%|█████████▏| 291/315 [10:31<00:54,  2.25s/it]\u001b[A\n",
      " 93%|█████████▎| 292/315 [10:34<00:53,  2.31s/it]\u001b[A\n",
      " 93%|█████████▎| 293/315 [10:36<00:47,  2.15s/it]\u001b[A\n",
      " 93%|█████████▎| 294/315 [10:38<00:46,  2.20s/it]\u001b[A\n",
      " 94%|█████████▎| 295/315 [10:40<00:43,  2.17s/it]\u001b[A\n",
      " 94%|█████████▍| 296/315 [10:42<00:41,  2.19s/it]\u001b[A\n",
      " 94%|█████████▍| 297/315 [10:44<00:35,  1.99s/it]\u001b[A\n",
      " 95%|█████████▍| 298/315 [10:45<00:29,  1.72s/it]\u001b[A\n",
      " 95%|█████████▍| 299/315 [10:46<00:25,  1.59s/it]\u001b[A\n",
      " 95%|█████████▌| 300/315 [10:48<00:26,  1.77s/it]\u001b[A\n",
      " 96%|█████████▌| 301/315 [10:51<00:27,  1.98s/it]\u001b[A\n",
      " 96%|█████████▌| 302/315 [10:52<00:23,  1.84s/it]\u001b[A\n",
      " 96%|█████████▌| 303/315 [10:54<00:21,  1.80s/it]\u001b[A\n",
      " 97%|█████████▋| 304/315 [10:56<00:21,  1.95s/it]\u001b[A\n",
      " 97%|█████████▋| 305/315 [10:59<00:20,  2.06s/it]\u001b[A\n",
      " 97%|█████████▋| 306/315 [11:01<00:20,  2.23s/it]\u001b[A\n",
      " 97%|█████████▋| 307/315 [11:04<00:18,  2.30s/it]\u001b[A\n",
      " 98%|█████████▊| 308/315 [11:05<00:13,  1.98s/it]\u001b[A\n",
      " 98%|█████████▊| 309/315 [11:07<00:12,  2.07s/it]\u001b[A\n",
      " 98%|█████████▊| 310/315 [11:10<00:10,  2.18s/it]\u001b[A\n",
      " 99%|█████████▊| 311/315 [11:12<00:08,  2.22s/it]\u001b[A\n",
      " 99%|█████████▉| 312/315 [11:14<00:06,  2.05s/it]\u001b[A\n",
      " 99%|█████████▉| 313/315 [11:15<00:03,  1.94s/it]\u001b[A\n",
      "100%|█████████▉| 314/315 [11:18<00:02,  2.06s/it]\u001b[A\n",
      "100%|██████████| 315/315 [11:20<00:00,  2.17s/it]\u001b[A\n",
      "\n",
      " 80%|████████  | 253/315 [11:20<15:12, 14.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 256/315 [11:20<09:50, 10.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 259/315 [11:21<06:25,  6.88s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 262/315 [11:21<04:12,  4.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 265/315 [11:21<02:45,  3.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 268/315 [11:21<01:49,  2.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 271/315 [11:21<01:11,  1.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 275/315 [11:21<00:41,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 278/315 [11:21<00:28,  1.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 281/315 [11:21<00:18,  1.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 285/315 [11:22<00:11,  2.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 288/315 [11:22<00:07,  3.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 291/315 [11:22<00:05,  4.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 294/315 [11:22<00:03,  5.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 297/315 [11:22<00:02,  7.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 300/315 [11:22<00:01,  9.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 303/315 [11:22<00:01, 10.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 306/315 [11:23<00:00, 12.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 309/315 [11:23<00:00, 13.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 311/315 [11:23<00:00, 13.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 313/315 [11:23<00:00, 13.71it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8260869565217391}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epoch * len(eval_dataloader) ))\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model_task_specific.train()\n",
    "    for batch in train_dataloader:\n",
    "        batch = { k: v.to(device) for k, v in batch.items() }\n",
    "        outputs = model_task_specific(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward() # computes gradients\n",
    "        \n",
    "        optimizer.step() # updates the weights and biases based on these gradients\n",
    "        lr_scheduler.step() # updates the weights and biases based on these gradients\n",
    "        optimizer.zero_grad() # used to clear the gradients of all parameters in a model\n",
    "        progress_bar_train.update(1)\n",
    "    \n",
    "    # run on validation set\n",
    "    model_task_specific.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = { k: v.to(device) for k, v in batch.items() }\n",
    "        with torch.no_grad(): # a context manager that disables gradient calculation during model inference\n",
    "            outputs = model_task_specific(**batch)\n",
    "            \n",
    "        logits = outputs.logits # calculates the probabilities between the labels\n",
    "        predictions = torch.argmax(logits, dim = -1 ) # takes the label closest to 1\n",
    "        metric.add_batch(predictions = predictions, references = batch['labels'] ) \n",
    "        progress_bar_eval.update(1)\n",
    "        \n",
    "    print(metric.compute()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1afd85-0cb0-4b59-988b-4eedf6722b90",
   "metadata": {},
   "source": [
    "# Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dd495290-88c6-47a7-be4a-31b2548d8ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 1, 0])\n",
      "New Batch\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "{'f1': 0.8316831683168316}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 315/315 [11:36<00:00, 13.71it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "model_task_specific.eval()\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset_cc['test'], batch_size = 32, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = { k: v.to(device) for k, v in batch.items() }\n",
    "    with torch.no_grad(): # a context manager that disables gradient calculation during model inference\n",
    "        outputs = model_task_specific(**batch)\n",
    "\n",
    "    logits = outputs.logits # calculates the probabilities between the labels\n",
    "    predictions = torch.argmax(logits, dim = -1 ) # takes the label closest to 1\n",
    "    metric.add_batch(predictions = predictions, references = batch['labels'] )\n",
    "    print(\"New Batch\")\n",
    "    print(predictions)\n",
    "    print(batch['labels'])\n",
    "\n",
    "print(metric.compute()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f6c113-be50-49c0-affd-e9127f99bd08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
